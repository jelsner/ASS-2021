---
title: "Lesson 25"
author: "James B. Elsner"
date: "April 7, 2021"
output:
  pdf_document: default
  html_document: null
editor_options:
  chunk_output_type: console
---

**"Statistics is such a powerful language for describing data in ways that reveal nothing about their causes. Of course statistics is powerful for revealing causes as well. But it takes some care. Like the difference between talking and making sense."** -- Richard McElreath

Last synchronous lesson. Next week the last two lessons on assorted topics in spatial statistics will be available as Rmd files that you can work through on your own if interested. The final assignment will be due _next_ Friday, April 16 at 3p. I will be available this Friday (but not next) for live help if needed. 

## Interpolating April temperatures across the Midwest

The data in `MidwestTemps.txt` are average temperatures in and around the state of Iowa for the month of April. The goal is a spatial interpolation of these values.

Step 1: Examine the data for spatial trends and normality.
```{r}
library(tidyverse)

L <- "http://myweb.fsu.edu/jelsner/temp/data/MidwestTemps.txt"
t.df <- read_table(L)
summary(t.df)
```

Map the values.
```{r}
library(sf)
library(tmap)
library(USAboundaries)

t.sf <- st_as_sf(x = t.df, 
                 coords = c("lon", "lat"),
                 crs = 4326)

sts <- us_states()

tm_shape(t.sf) +
  tm_text(text = "temp", size = .6) +
tm_shape(sts) +
  tm_borders() 
```

Create a `geodata` object from the data frame.
```{r}
library(geoR)

t.gdf <- as.geodata(t.df)
summary(t.gdf)
plot(t.gdf)
```

The maximum pairwise distance is 11.5 degrees. There is a pronounced 1st order trend in the north/south direction as we might expect with air temperatures.

Remove the non-linear trend and examine the residuals.
```{r}
plot(t.gdf, 
     trend = "2nd")
```

By specifying a higher order trend, the lower order trends are taken care of. The distribution of residuals is approximately normal as we might expect. The data are monthly means.

Step 2: Compute empirical variograms. Check for anisotropy (correlations are more persistent in a particular direction) by plotting directional variograms.
```{r}
plot(variog4(t.gdf, 
             trend = "2nd", 
             max.dist = 5.5), 
     omni = TRUE, 
     legend = FALSE)
```

There is no strong evidence to reject isotropy.

Fit a variogram model to the data. Here we consider several likelihood fits to an exponential model and examine the AIC for final parameter selection.  The AIC is used as a selection criterion and is a function of the maximized likelihood function but includes a penalty for model complexity that favors simpler models. Recall the best fit has the largest log-likelihood and smallest AIC.  

Set initial values for the sill and range. From the variograms we start with 3 for the sill and 4 for the range.
```{r}
iv <- c(3, 4)  
summary(likfit(t.gdf, 
               ini = iv, 
               cov.model = "exp", 
               trend = "2nd",
               fix.nug = TRUE, 
               message = FALSE))$likelihood$AIC
summary(likfit(t.gdf, 
               ini = iv, 
               cov.model = "exp", 
               trend = "2nd",
               fix.nug = FALSE, 
               message = FALSE))$likelihood$AIC
summary(likfit(t.gdf, ini = iv, 
               cov.model = "sph", 
               trend = "2nd",
               fix.nug = TRUE, 
               message = FALSE))$likelihood$AIC
summary(likfit(t.gdf, ini = iv, 
               cov.model = "sph", 
               trend = "2nd",
               fix.nug = FALSE, 
               message = FALSE))$likelihood$AIC
```

It appears that a good variogram model on the residuals would be an exponential function with fixed nugget equal to zero. A spherical function with a nugget is also a reasonable model.

To obtain the model parameters, type
```{r}
likfit(t.gdf, ini = iv, cov.model = "exp", 
       trend = "2nd", fix.nug = TRUE)
likfit(t.gdf, ini = iv, cov.model = "sph", 
       trend = "2nd", fix.nug = FALSE)
```

Plot the competing models on the empirical variogram.
```{r}
plot(variog(t.gdf, trend = "2nd", 
            uvec = seq(0, 5.5, l = 29)))
lines.variomodel(cov.model = "exp", 
                 cov.pars = c(2.114, .4139), 
                 nug = 0, max.dist = 5.5, col = "red")
lines.variomodel(cov.model = "sph", 
                 cov.pars = c(1.638, 1.307),
                 nug =.5, max.dist = 5.5, col = "green")
```

Save the models.
```{r}
modelE <- likfit(t.gdf, ini = iv, cov.model = "exp", 
                  trend = "2nd", fix.nug = TRUE)
modelS <- likfit(t.gdf, ini = iv, cov.model = "sph", 
                  trend = "2nd", fix.nug = FALSE)
```

Create an interpolated surface. We create a grid of locations at which we want the temperatures to be interpolated. Here we use the `expand.grid` function where the arguments are the sequence of longitudes and latitudes, respectively. We then use the `krige.conv()` function to interpolate the values to the grid. We save the interpolation in `kcE` when we use the exponential variogram model to weight the observations and save the interpolation in `kcS` when we use the spherical model to weight the observations.
```{r}
pgrid.df<- expand.grid(lon = seq(-99, -88, l = 224), 
                       lat = seq(38.4, 45.4, l = 136))
kcE <- krige.conv(t.gdf, 
                  loc = pgrid.df, 
                  krige = krige.control(trend.d = "2nd", 
                                       trend.l = "2nd",
                                       obj.m = modelE))
kcS <- krige.conv(t.gdf, 
                  loc = pgrid.df,
                  krige = krige.control(trend.d = "2nd", 
                                       trend.l = "2nd",
                                       obj.m = modelS))
```

Plot the interpolated surface. A quick plot is made with the `image()` function.
```{r}
image(kcE)
```

To create a more publishable version we create a raster then use the functions from the {tmap} package.
```{r}
library(sp)

pgrid.df$temp <- kcE$predict
pgrid.df$var <- kcE$krige.var

spdf <- pgrid.df
coordinates(spdf) <- c("lon", "lat")
spdf <- as(spdf, "SpatialPixelsDataFrame")
proj4string(spdf) <- st_crs(t.sf)$proj4string

library(raster)
r <- raster(spdf)

tm_shape(r) +
  tm_raster(n = 9, palette = "OrRd") +
tm_shape(sts) +
  tm_borders() +
tm_shape(t.sf) +
  tm_text("temp", size = .5)
```

Plot the interpolated surface generated using the spherical variogram.
```{r}
pgrid.df$temp <- kcS$predict
pgrid.df$var <- kcS$krige.var

spdf <- pgrid.df
coordinates(spdf) <- c("lon", "lat")
spdf <- as(spdf, "SpatialPixelsDataFrame")
proj4string(spdf) <- st_crs(t.sf)$proj4string

library(raster)
r <- raster(spdf)

tm_shape(r) +
  tm_raster(n = 9, palette = "OrRd") +
tm_shape(sts) +
  tm_borders() +
tm_shape(t.sf) +
  tm_text("temp", size = .5)
```

The model with a non-zero nugget is smoother. The greater the nugget relative to the sill (relative nugget effect), the smoother the interpolation.

## Spatial statistical interpolation using functions from the {gstat} package

In 2008, Tropical Cyclone Fay formed from a tropical wave near the Dominican Republic, passed over the island of Hispaniola, Cuba, and the Florida Keys, then crossed the Florida peninsula and moved westward across portions of the panhandle producing heavy rains in parts of the state.

Storm total rainfall amounts from stations in and around the state are in `FayRain.txt`. They are a compilation of reports from the U.S. NOAA/NWS official weather sites and coop sites.

The coop sites are the Community Collaborative Rain, Hail and Snow Network (CoCoRaHS), a community-based, high density precipitation network made up of volunteers who take measurements of precipitation in their backyards. The data were obtained from NOAA/NCEP/HPC and from the Florida Climate Center.

Load the data.
```{r}
L <- "http://myweb.fsu.edu/jelsner/temp/data/FayRain.txt"
FR.df <- read.table(L, header = TRUE)
names(FR.df)
```

The data frame contains 803 rainfall sites. Longitude and latitude coordinates of the sites are given in the first two columns and total rainfall in inches and millimeters are given in the second two columns. Create a spatial points data frame by specifying columns that contain the spatial coordinates. Then assign a geographic coordinate system and convert the rainfall from millimeters to centimeters.
```{r}
library(sf)

FR.sf <- st_as_sf(x = FR.df,
                 coords = c("lon", "lat"),
                 crs = 4326)

FR.sf$tpm <- FR.sf$tpm/10
summary(FR.sf$tpm)
```

The median value is 15.8 cm and the maximum is 60.2 cm. 

Next get the Florida county boundaries from the {USAboundaries} package.
```{r}
FL.sf <- USAboundaries::us_counties(states = "Florida")
```

Next we create a character string specifying the tags for a planar projection and transform the geographic coordinates of the site locations and map polygons to the projected coordinates. Here we use Florida GDL Albers (EPSG:3087) with meter as the distance unit.

```{r}
FR.sf <- st_transform(FR.sf, crs = 3087)
FL.sf <- st_transform(FL.sf, crs = 3087)
```

A map of the rainfall sites and storm totals with the state boundaries is made by typing
```{r}
library(tmap)

tm_shape(FR.sf) +
  tm_dots(col = "tpm", size = 1) +
tm_shape(FL.sf) +
  tm_borders()
```

Two areas of heavy rainfall are noted.  One running north-south along the east coast and another across the north. Rainfall collection sites are clustered in and around cities. This will make it difficult to use a spline interpolation.

Rainfall is an example of geostatistical data. In principle it can be measured anywhere, but typically we have values at a sample of sites. The pattern of observation sites is not of much interest as it is a consequence of constraints (convenience, opportunity, economics, etc) unrelated to the phenomenon. Interest centers on inference about how much rain fell across the region.

The empirical variogram is computed using the `variogram()` function. The first argument is the model formula specifying the rainfall column from the data frame and the second argument is the data frame name.  Here `~ 1` in the model formula indicates no covariates or trends in the data. Trends can be included by specifying coordinate names through the `st_coordinates()` function.

We compute the empirical variogram for Fay's rainfall and save it by typing
```{r}
library(gstat)

FR.v <- variogram(tpm ~ 1, 
                  data = FR.sf)
```

We plot the variogram values as a function of lag distance and add text indicating the number of point pairs for each lag distance.
```{r}
library(ggplot2)

v.df <- data.frame(dist = FR.v$dist/1000,
                   gamma = FR.v$gamma,
                   np = FR.v$np)

( pv <- ggplot(v.df, aes(x = dist, y = gamma)) +
  geom_point() +
  geom_text(aes(label = np), nudge_y = -5) +
  scale_y_continuous(limits = c(0, 220)) +
  scale_x_continuous(limits = c(0, 400)) +
  xlab("Lagged distance (h) [km]") +
  ylab(expression(paste("Semivariance (", gamma, ") [", cm^2, "]"))) +
  theme_minimal() )
```

Values start low (~50 cm$^2$) at short lag distance, then increase to over 200 cm$^2$ at lag distance of about 200 km.

The zero-lag semivariance is called the 'nugget' and the semivariance at a level where the variogram values no longer increase is called the 'sill.'  The lag distance to the sill is called the 'range.'  These three parameters (nugget, sill, and range) are used to fit a model to the variogram.

Next we fit a model to the empirical variogram. The variogram model is a mathematical relationship defining the semivariance as a function of lag distance. We first save the family and the initial parameter guesses in a variogram model (`FR.vmi`) object by typing
```{r}
FR.vmi <- vgm(model = "Gau", 
              psill = 150, 
              range = 200 * 1000, 
              nugget = 50)
FR.vmi
```

The `psill` argument is the partial sill as the difference between the sill and the nugget. We get estimates of the parameter values from looking at the empirical variogram. 

Next we use the `fit.variogram()` function to improve the fit.  Given a set of initial parameter values, the method of weighted least squares improves the parameter estimates. Ordinary least squares is not appropriate as the semivariances are correlated across the lag distances and the precision on the estimates varies depending on the number of site pairs for a given lag.
```{r}
FR.vm <- fit.variogram(object = FR.v, 
                       model = FR.vmi)
FR.vm
```

The result is a variogram model with a nugget of 46.8 cm$^2$, a partial sill of 157 cm$^2$, and a range on the sill of 129 km. 

Let $r$ be the range, $c$ the partial sill and $c_o$ the nugget, then the equation defining the curve over the set of lag distances $h$ is
$$
\gamma(h)=c\left(1-\exp\left(-\frac{h^2}{r^2}\right)\right)+c_o
$$

We create a data frame with values of h and gamma using this equation.

```{r}
nug <- FR.vm$psill[1]
ps <- FR.vm$psill[2]
r <- FR.vm$range[2] / 1000
h <- seq(0, 400, .2)
gamma <- ps * (1 - exp(-h^2 / (r^2))) + nug

vm.df <- data.frame(dist = h,
                    gamma = gamma)

pv + geom_line(aes(x = dist, y = gamma), data = vm.df)
```

Check for anisotropy.
```{r}
plot(variogram(tpm ~ 1, 
               data = FR.sf, 
               alpha = c(0, 45, 90, 135)), 
     xlab = "Lag Distance (m)")
```

We see the range of correlations is longer (about 300 km) in the north-south direction (0 degrees). We refit the variogram defining an anistropy ellipse with the `anis =` argument. The first parameter is the direction of longest range and the second parameter is the ratio of the longest to shortest. Here about (200/300 = .67).
```{r}
FR.vmi <- vgm(model = "Gau", 
              psill = 150, 
              range = 300 * 1000, 
              nugget = 50,
              anis = c(0, .67))
FR.vm <- fit.variogram(FR.v, FR.vmi)
```

The final step is to use the variogram model together with the rainfall values at the observation sites to create an interpolated surface. Here we use _ordinary_ kriging as there are no spatial trends in the rainfall.

Interpolation is done using the `krige()` function. The first argument is the model specification and the second is the data. Two other arguments are needed. One is the variogram model using the argument name model and the other is a set of locations identifying where the interpolations are to be made. This is specified with the argument name `newdata =`.

Here we interpolate to locations on a regular grid. We create a grid of locations within the boundary of Florida using the `st_sample()` function.
```{r}
grid.sf <- st_sample(FL.sf,
                     size = 5000,
                     type = "regular")
```

We specify the number of locations using the argument `size =`. Note that the actual number of locations will be somewhat different because of the irregular boundary. 

First we use the `krige()` function to interpolate the observed rainfall to the grid locations. Recall that for a given location, the interpolation is a weighted average of the rainfall across the entire region where the weights are determined by the variogram model.
```{r}
ipl <- krige(tpm ~ 1, 
             locations = FR.sf, 
             newdata = grid.sf,
             model = FR.vm)
```

If the variogram model is not included then inverse distance weighted interpolation is performed. The function will not work if different values share the same location. 

The saved object (`ipl`) inherits the spatial object specified in the `newdata` argument, but extends it to a spatial data frame. The data frame with two variables.  The first `var1.pred` is the interpolated rainfall and the second `var1.var` is the prediction variance.

We plot the interpolated field.
```{r}
tm_shape(ipl) +
  tm_dots("var1.pred",
          size = .1,
          palette = "Greens",
          title = "Rainfall (cm)") +
  tm_shape(FL.sf) +
  tm_borders() +
  tm_layout(legend.position = c("left", "bottom"),
            title = "Tropical Cyclone Fay (2008)",
            title.position = c("left", "bottom"))
```

Note that a portion of the data values where outside of the state but our interest is only to have values on a grid within the state. 

The spatial interpolation shows that parts of east central and north Florida were deluged by Fay.

We use _block_ kriging to estimate average rainfall within each county. The county-wide rainfall average is relevant for water resource managers. Block kriging produces a smoothed estimate of this area average, which will differ from a simple average over all sites within the county because of spatial autocorrelation.

We use the same function to interpolate but specify the spatial polygons rather than the spatial grid as the new data.
```{r}
ipl2 <- krige(tpm ~ 1, 
              locations = FR.sf, 
              newdata = FL.sf, 
              model = FR.vm)
```

Again we plot the interpolations.
```{r}
tm_shape(ipl2) +
  tm_polygons(col = "var1.pred",
            palette = "Greens",
            title = "Rainfall (cm)") +
  tm_layout(legend.position = c("left", "bottom"),
            title = "Tropical Cyclone Fay (2008)",
            title.position = c("left", "bottom"))
```

The overall pattern of rainfall from Fay featuring the largest amounts along the central east coast and over the eastern panhandle are similar in both maps.

We compare the kriged average with the simple average at the county level with `aggregate()` from the {sf} package.
```{r}
ipl3 <- aggregate(FR.sf, by = FL.sf, FUN = mean)
```

The function returns a simple feature data frame of the average rainfall in each county.

The state-wide mean of the kriged estimates at the county level is 
```{r}
round(mean(ipl2$var1.pred), 2)
```

This compares with a state-wide mean from the simple averages.
```{r}
round(mean(ipl3$tpm), 2)
```

The correlation between the two estimates across the 67 counties is 
```{r}
round(cor(ipl3$tpm, ipl2$var1.pred), 2)
```

The variogram model reduces the standard deviation of the kriged estimate relative to the standard deviation of the simple averages because of the local smoothing.
```{r}
round(sd(ipl2$var1.pred), 2)
round(sd(ipl3$tpm), 2)
```

This can be seen with a scatter plot of simple averages versus kriged averages at the county level.
```{r}
compare.df <- data.frame(simpleAvg = ipl3$tpm,
                         krigeAvg = ipl2$var1.pred)
ggplot(compare.df, aes(x = simpleAvg,
                       y = krigeAvg)) +
  geom_point() +
  geom_abline(slope = 1) +
  geom_smooth(method = lm, se = FALSE)
```

An advantage of kriging as a method of spatial interpolation is the accompanying uncertainty estimates. The prediction variances are listed in a column in the spatial data frame saved from apply the `krige()` function. Variances are smaller in regions with more rainfall observations.  

Prediction variances are also smaller with block kriging as much of the variability within the county averages out. To compare the distribution characteristics of the prediction variances for the point and block kriging of the rainfall observations, type
```{r}
round(summary(ipl$var1.var), 1)
round(summary(ipl2$var1.var), 1)
```

The median prediction variance (in cm$^2$) for our point kriging is close to the value of the nugget.
```{r}
round(fivenum(ipl$var1.var)[3], 1)
```

In contrast the median prediction variance for our block kriging is a much smaller 
```{r} 
round(fivenum(ipl2$var1.var)[3], 1)
```

Simulations exploit this uncertainty and provide synthetic data for use in deterministic models. 

Conditional simulation, where the simulated field (realization) is generated given the data and the variogram model, is done using the same `krige()` function by adding the argument `nsim` to specify the number of simulations.  

For a large number it may be necessary to limit the number neighbors in the kriging. This is done using the `nmax` argument. For a given location, the weights assigned to observations far away are very small, so it is efficient to limit how many are used in the simulation.

As an example, here we generate four realizations of the county-level storm total rainfall for Fay and limit the neighborhood to 50 of the closest observation sites. Note that it may take a few seconds.
```{r}
ipl.sim <- krige(tpm ~ 1, 
                 locations = FR.sf, 
                 newdata = FL.sf, 
                 model = FR.vm, 
                 nsim = 4, 
                 nmax = 50)
```

Simulations are conditional on the observed rainfall and the variogram model using block kriging on the counties.

```{r}
library(tmap)

tm_shape(ipl.sim) +
    tm_polygons(col = c("sim1", "sim2", "sim3", "sim4"),
                palette = "Greens",
                title = "Simulated Rainfall [cm]") +
    tm_facets(free.scales = FALSE) 
```

The overall pattern of rainfall remains the same, but there are differences especially in counties with fewer observations and in counties where the rainfall gradients are sharp.