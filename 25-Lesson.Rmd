---
title: "Lesson 25"
author: "James B. Elsner"
date: "April 7, 2021"
output:
  html_document: null
editor_options:
  chunk_output_type: console
---

**"Statistics is such a powerful language for describing data in ways that reveal nothing about their causes. Of course statistics is powerful for revealing causes as well. But it takes some care. Like the difference between talking and making sense."** -- Richard McElreath


## Example 2: April temperatures in the Midwest

The data in `MidwestTemps.txt` are average temperatures in and around the state of Iowa for the month of April. The goal is a spatial interpolation of these values onto a 56 by 35 grid.

Step 1: Examine the data for spatial trends and normality.
```{r}
L <- "http://myweb.fsu.edu/jelsner/temp/data/MidwestTemps.txt"
t.df <- read.table(L, header = TRUE)
summary(t.df)
```

Map the values.
```{r}
t.sf <- st_as_sf(x = t.df, 
                 coords = c("lon", "lat"),
                 crs = "+proj=longlat +datum=WGS84")

tm_shape(t.sf) +
  tm_text(text = "temp", size = .6) +
tm_shape(sts) +
  tm_borders() 
```

Create a `geodata` object from the data frame.
```{r}
t.gdf <- as.geodata(t.df)
summary(t.gdf)
plot(t.gdf)
```

The maximum pairwise distance is 11.5 degrees. There is a pronounced 1st order trend in the north/south direction as we might expect with air temperatures.

Remove the trend and examine the residuals.
```{r}
plot(t.gdf, trend = "1st")
```

There is some evidence of a 2nd-order trend in the west-east direction. 
```{r}
plot(t.gdf, trend = "2nd")
```

By specifying a higher order trend, the lower order trends are taken care of. The distribution of residuals is approximately normal as we might expect. The data are monthly means.

Step 2: Compute empirical variograms. Check for anisotropy by plotting directional variograms.
```{r}
par(mfrow = c(1, 1))
plot(variog4(t.gdf, trend = "2nd", 
             max.dist = 5.5), 
     omni = TRUE, legend = FALSE)
```

There is no strong evidence to reject isotropy.

Step 3: Fit a variogram model to the data. Here we consider several likelihood fits to an exponential model and examine the AIC for final parameter selection. 

The AIC is used as a selection criterion and is a function of the maximized likelihood function but includes a penalty for model complexity that favors simpler models. Recall the best fit has the largest log-likelihood and smallest AIC.  

Set initial values for the sill and range. From the variograms start with 3 for the sill and 4 for the range.
```{r}
iv <- c(3, 4)  
summary(likfit(t.gdf, 
               ini = iv, 
               cov.model = "exp", 
               trend = "2nd",
               fix.nug = TRUE, 
               message = FALSE))$likelihood$AIC
summary(likfit(t.gdf, 
               ini = iv, 
               cov.model = "exp", 
               trend = "2nd",
               fix.nug = FALSE, 
               message = FALSE))$likelihood$AIC
summary(likfit(t.gdf, ini = iv, 
               cov.model = "sph", 
               trend = "2nd",
               fix.nug = TRUE, 
               message = FALSE))$likelihood$AIC
summary(likfit(t.gdf, ini = iv, 
               cov.model = "sph", 
               trend = "2nd",
               fix.nug = FALSE, 
               message = FALSE))$likelihood$AIC
```

It appears that a good variogram model would be on the residuals of a 2nd order trend using an exponential function with fixed nugget equal to zero. A spherical function with a nugget is also a reasonable model.

To obtain the model parameters, type
```{r}
likfit(t.gdf, ini = iv, cov.model = "exp", 
       trend = "2nd", fix.nug = TRUE)
likfit(t.gdf, ini = iv, cov.model = "sph", 
       trend = "2nd", fix.nug = FALSE)
```

Plot the competing models on the empirical variogram.
```{r}
plot(variog(t.gdf, trend = "2nd", 
            uvec = seq(0, 5.5, l = 29)))
lines.variomodel(cov.model = "exp", 
                 cov.pars = c(2.114, .4139), 
                 nug = 0, max.dist = 5.5, col = "red")
lines.variomodel(cov.model = "sph", 
                 cov.pars = c(1.638, 1.307),
                 nug =.5, max.dist = 5.5, col = "green")
```

Save the models.
```{r}
modelE <- likfit(t.gdf, ini = iv, cov.model = "exp", 
                  trend = "2nd", fix.nug = TRUE)
modelS <- likfit(t.gdf, ini = iv, cov.model = "sph", 
                  trend = "2nd", fix.nug = FALSE)
```

Step 4: Create an interpolated surface. We create a grid of locations at which we want the temperatures to be interpolated. Here we use the `expand.grid` function where the arguments are the sequence of longitudes and latitudes, respectively. We then use the `krige.conv()` function to interpolate the values to the grid. We save the interpolation in `kcE` when we use the exponential variogram model to weight the observations and save the interpolation in `kcS` when we use the spherical model to weight the observations.
```{r}
pgrid.df<- expand.grid(lon = seq(-99, -88, l = 224), 
                       lat = seq(38.4, 45.4, l = 136))
kcE <- krige.conv(t.gdf, 
                  loc = pgrid.df, 
                  krige = krige.control(trend.d = "2nd", 
                                       trend.l = "2nd",
                                       obj.m = modelE))
kcS <- krige.conv(t.gdf, 
                  loc = pgrid.df,
                  krige = krige.control(trend.d = "2nd", 
                                       trend.l = "2nd",
                                       obj.m = modelS))
```

Plot the interpolated surface generated using the exponential variogram. function.
```{r}
pgrid.df$temp <- kcE$predict
pgrid.df$var <- kcE$krige.var

spdf <- pgrid.df
coordinates(spdf) <- c("lon", "lat")
spdf <- as(spdf, "SpatialPixelsDataFrame")
proj4string(spdf) <- st_crs(t.sf)$proj4string

library(raster)
r <- raster(spdf)

tm_shape(r) +
  tm_raster(n = 9, palette = "OrRd") +
tm_shape(sts) +
  tm_borders() +
tm_shape(t.sf) +
  tm_text("temp", size = .5)
```

Plot the interpolated surface generated using the spherical variogram.
```{r}
pgrid.df$temp <- kcS$predict
pgrid.df$var <- kcS$krige.var

spdf <- pgrid.df
coordinates(spdf) <- c("lon", "lat")
spdf <- as(spdf, "SpatialPixelsDataFrame")
proj4string(spdf) <- st_crs(t.sf)$proj4string

library(raster)
r <- raster(spdf)

tm_shape(r) +
  tm_raster(n = 9, palette = "OrRd") +
tm_shape(sts) +
  tm_borders() +
tm_shape(t.sf) +
  tm_text("temp", size = .5)
```

The model with a non-zero nugget is smoother. The greater the nugget relative to the sill (relative nugget effect), the smoother the interpolation.

## Combine prediction and uncertainty in a single map

See `Pixelate.Rmd`.

## Synthetic data

Synthetic data are useful as input to a deterministic model. An example is rainfall as input to spatially-distributed rainfall-runoff model. Interpolated values of precipitation and their variances might be of little value, but running the rainfall-runoff model with a large number of simulated rainfall fields can give a realistic assessment of the uncertainty in runoff arising from the variability in the rainfall.

The `grf()` function in the {geoR} package generates synthetic data from Gaussian random fields on regular or irregular sets of locations. For example, to generate 100 randomly spaced points with values at the points being a sample from a Gaussian random field with an exponential variogram (default with zero nugget) having a sill of 1 and a range of .25, type
```{r}
set.seed(3042)
sim1 <- grf(100, cov.pars = c(1, .25))
```

Plot the points and the variograms.
```{r}
layout(matrix(c(1, 2), byrow = TRUE, ncol = 2), 
       respect = TRUE)
points.geodata(sim1, 
               main = "simulated locations and values")
plot(sim1, max.dist = .5, 
     main = "true and empirical variograms")
```

The random fields can be put on a regular grid.
```{r}
sim2 <- grf(441, grid = "reg", cov.pars = c(1, .25))
image(sim2, col = gray(seq(1, .1, l = 30)))
sim3 <- grf(4441, grid = "reg", cov.pars = c(1, .25))
image(sim3, col = gray(seq(1, .1, l = 30)))
par(mfrow = c(1, 1))
```

For an even higher resolution simulation it is necessary to have the {RandomFields} package.
```{r, eval=FALSE}
library(RandomFields)
sim4 <- grf(40401, grid = "reg", cov.pars = c(10, .2))
image(sim4, main = "simulation on a fine grid", 
      col = gray(seq(1, .1, l = 30)))
```

## Interpolation using functions from the {gstat} package

We start with the Meuse river data from Burrough and McDonnell (1998). The data are part of {gstat}.

Convert to {sf} object first? See Tropical cyclone rainfall example.
```{r}
library(gstat)
library(sp)

data(meuse)
head(meuse)
```

The data are topsoil heavy metal concentrations along with a number of soil and landscape variables at locations in a flood plain of the river Meuse near the town of Stein (NL).

Heavy metal concentrations are composite samples of an area of approximately 15 m x 15 m. The dataset also gives local elevation (m) above local river bed and distance to river normalized to a value between 0 and 1.

Create a spatial points data frame (S4 class) and map the concentration of zinc in the soil on a log scale as a bubble plot.
```{r}
coordinates(meuse) <- ~ x + y
proj4string(meuse) <- CRS("+init=epsg:28992")
class(meuse)
bubble(meuse, "zinc", 
       do.log = TRUE, 
       key.space = "bottom")
```

Zinc in the soil is concentrated along the east bank of the Meuse river.

### Inverse-distance weighting

We begin by creating an interpolated surface with the method of inverse distance weighting (IDW). Here the average of the observed values for any location is weighted inversely based on how far the observation points are from the location of interest. An exponent on the weights matrix determines the degree to which nearer observations are weighted more than more distant ones. 

A regular grid where the interpolated values of zinc are made is given in the data frame `meuse.grid`. 
```{r}
data(meuse.grid)
head(meuse.grid)
```

Convert the grid as a data frame to a spatial pixels data frame. Note this is done first by converting the data frame to spatial points then to spatial pixels.
```{r}
coordinates(meuse.grid) <- ~ x + y
proj4string(meuse.grid) <- CRS("+init=epsg:28992")
meuse.grid2 <- as(meuse.grid, "SpatialPixelsDataFrame") 
head(meuse.grid2)
```

As mentioned last time, the above conversion works since the locations have a spatial ordering. It will not work for a data frame with an arbitrary ordering of locations. 

Here we plot the pixel locations using the attribute `dist` indicating distance to the river.
```{r}
library(tmap)

tm_shape(meuse.grid2) +
  tm_raster("dist")
```

Interpolate the zinc values to the pixel locations using IDW. The `idp = ` argument is the exponent on the weights. The larger the exponent, the more variation there is in the interpolated values.
```{r}
zinc.idw <- idw(zinc ~ 1, 
                meuse, 
                newdata = meuse.grid2, 
                idp = 2.5)
str(zinc.idw, max.level = 3)
```

Note the formula. Here `zinc ~ 1`, where `zinc` is the field variable that is to be interpolated and 1 indicates a IDW interpolation (no autocorrelation and no trend or covariates).

The saved object (`zinc.idw`) inherits the class of the interpolation grid (here `SpatialPixelDataFrame`). The interpolated values are saved in the data frame slot with variable name `var1.pred`. The other variable is `var1.var` which is an estimate of the interpolation errors. With IDW they are `NA`.

IDW results in a surface that is often similar to a kriged surface. But interpolations may show undesired effects if the observation locations have a non-uniform distribution.

Map the results. Start with an image plot, then add a bubble plot of the observed concentrations and a legend. Here the size of the point character (circle) is set by the `cex = argument`.
```{r}
tm_shape(zinc.idw) +
  tm_raster("var1.pred") +
tm_shape(meuse) +
  tm_bubbles("zinc", alpha = .3)
```

IDW tends to generate 'bulls-eye' patterns.

The spatial class makes it easier to create maps and export them to different platforms.

### Distance to river as a covariate

Here you use distance to river as a covariate. It is a trend model for the spatial variability of zinc using a covariate defined by the square root of the distance to river. This is not kriging since no variogram model is used. 
```{r}
zn.lm <- krige(log(zinc) ~ sqrt(dist), 
               locations = meuse, 
               newdata = meuse.grid)

tm_shape(zn.lm) +
  tm_raster("var1.pred")
```

Note that the spacing in colors is not linear.

### Empirical variogram analysis

The `variogram()` function from {gstat} computes the empirical variogram. Here the trend is not in the cardinal directions but rather in distance to the river. The variogram is on the residuals from this trend.
```{r}
meuse.v <- variogram(log(zinc) ~ sqrt(dist), 
                     data = meuse)
plot(meuse.v, xlab = "Lag Distance (m)")
```

The default cutoff lag (`cutoff`) and lag tolerance (`width`) can be changed. For example, type
```{r}
plot(variogram(log(zinc) ~ sqrt(dist), 
               data = meuse, 
               cutoff = 1000, 
               width = 50), 
      xlab = "Lag Distance (m)")
```

For comparison, plot a variogram of residuals after removing a 1st-order trend in direction.
```{r}
plot(variogram(log(zinc) ~ x + y, 
               data = meuse, 
               cutoff = 1000, 
               width = 50), 
     xlab = "Lag Distance (m)")
```

Directional variograms are estimated by adding the argument alpha.
```{r}
plot(variogram(log(zinc) ~ x + y, 
               data = meuse, 
               cutoff = 1000, 
               width = 50, 
               alpha = c(0, 45, 90, 135)), 
     xlab = "Lag Distance (m)")
```

The variogram in the sw-ne direction appears to be different. And there appears to be very little spatial autocorrelation in the n-s direction. This is partly due to the anistropy of the domain.

### Variogram maps

Another way of looking at directional dependence in semivariograms is with variogram maps. Instead of classifying point pairs $Z(s)$ and $Z(s + h)$ by direction and distance separately, they are classified jointly. 

If $h = (x, y)$ is the two-dimensional coordinates of the separation vector, in the variogram map the semivariance contribution of each point pair $(Z(s) - Z(s + h))^2$ is attributed to the grid cell in which $h$ lies. The map is centered at (0, 0), as $h$ is geographical distance rather than geographical location. 

Cutoff and width correspond to map extent and cell size; the semivariance map is point symmetric around (0, 0), as $\gamma(h) = \gamma(-h)$. 

The variogram map is obtained with the `map = TRUE` argument. The threshold assures that only semivariogram map values based on at least 5 point pairs are shown, removing too noisy estimation. 
```{r}
meuse.vmap <- variogram(log(zinc) ~ x + y, 
                        data = meuse, 
                        cutoff = 1500, 
                        width = 100,
                        map = TRUE)
plot(meuse.vmap, threshold = 5)
```

The symmetry about the dx, dy = (0, 0) is apparent. The variances range from 0 to 2.5 and appear to elongate along the long axis of the domain.

Compare with a variogram map when the square root of the distance to river is used as a covariate.
```{r}
meuse.vmap <- variogram(log(zinc) ~ sqrt(dist), 
                        data = meuse, 
                        cutoff = 1500, 
                        width = 100,
                        map = TRUE)
plot(meuse.vmap, threshold = 5)
```

The variances range from 0 to .8 and the directional dependence is much less obvious in this case.

### Variogram modeling

A plot of the model families is available with the `show.vgms()` function.
```{r}
show.vgms() 
```

We've seen the exponential (`Exp`), spherical (`Sph`), and Gaussian (`Gau`) families when working with the functions in the {geoR} package.

After choosing a family starting values are needed in the `fit.variogram()` function. The function calls the `vgm()` function that includes initial guesses for the partial sill (`psill`), the range (`range`), and the nugget (`nugget`) and uses a weighted least squares method.
```{r}
meuse.vm <- fit.variogram(meuse.v, 
                          vgm(model = "Sph", 
                              psill = .15,
                              range = 800, 
                              nugget = .1))
meuse.vm
```

The output includes a 2 x 2 table with the first row giving information about the nugget and the second giving information about the rest of the model. Here the nugget is .08. By definition the range is zero. The partial sill is .15 with a range of 872.7 m. Plot the sample variogram and the variogram model.
```{r}
plot(meuse.v, meuse.vm, 
     xlab = "Lag distance (m)")
```

The `fit.variogram` function refines the initial estimates given in the `vgm` function. If our initial choice is poor the fit may not work.  For example try
```{r}
fit.variogram(meuse.v, 
              vgm(model = "Sph",
                  psill = 1, 
                  range = 10, 
                  nugget = 1))
```

An argument for visual fitting over numerical fitting is when you have knowledge that goes beyond the information in the data. Information may come from other studies or derived from measurement error characteristics for a specific measuring device (nugget effect).

### Kriging

Simple kriging is done when there is no trend and the mean height of the surface is provided. Because you know the mean exactly you also know the residuals exactly at the data locations. If you know the residuals exactly then you can do a better job of estimating the autocorrelation function (variogram). For ordinary kriging you estimate the mean so the residuals are also estimates.

Universal kriging is done when there is a trend. With universal kriging both the trend and spatial variability are estimated in tandem.

Here we apply kriging to the logarithm of the zinc concentration using the fitted variogram model.
```{r}
lz.sk <- krige(formula = log(zinc) ~ 1, 
               locations = meuse, 
               newdata = meuse.grid, 
               model = meuse.vm, 
               beta = 5.9)
lz.ok <- krige(formula = log(zinc) ~ 1, 
               locations = meuse, 
               newdata = meuse.grid, 
               model = meuse.vm)
lz.uk <- krige(formula = log(zinc) ~ sqrt(dist),
               locations = meuse, 
               newdata = meuse.grid, 
               model = meuse.vm)

m1 <- tm_shape(lz.sk) +
        tm_raster("var1.pred", title = "Simple")

m2 <- tm_shape(lz.ok) +
        tm_raster("var1.pred", title = "Ordinary")

m3 <- tm_shape(lz.uk) +
        tm_raster("var1.pred", title = "Universal")

tmap_arrange(m1, m2, m3, ncol = 3)
```

Simple and ordinary kriging treat all spatial variation as autocorrelation. Universal kriging lets some of the variation be due to trend and covariates.

Predictive skill.