---
title: "Lesson 7"
author: "James B. Elsner"
date: "February 1, 2021"
output:
  html_document: null
editor_options:
  chunk_output_type: console
---

**"Hell isn't other people's code. Hell is your own code from 3 years ago."** â€“ Jeff Atwood

Today: Working with spatial data in R, creating subsets of simple feature data frames, joining data frames, and interpolating variables using areal weights.

## Creating attribute (variable) subsets

Variables (stored as columns) in a simple feature data frame are referred to as 'attributes'. We can create a subset of the data using the {base} R functions including `[`, `subset()` and `$` and  the{tidyverse} functions including `select()`, `filter()`, and `pull()`.

The `[` operator subsets rows and columns. Indexes specify the elements we wish to extract from an object, e.g. object[i, j], with i and j typically being numbers representing rows and columns. Leaving i or j empty returns all rows or columns, so `world[1:5, ]` returns the first five rows and all columns of the simple feature data frame `world`. 

Examples
```{r}
library(sf)
library(spData)

world[c(1, 5, 9), ] # subset rows by row position
world[, 1:3] # subset columns by column position
world[, c("name_long", "lifeExp")] # subset columns by name
```

Here we use logical vectors for creating a subset. First we create a logical vector `sel_area`.
```{r}
sel_area <- world$area_km2 < 10000
head(sel_area)
summary(sel_area)
```

And then we select only cases from the `world` simple feature data frame where the elements of the `sel_area` vector are `TRUE`.
```{r}
small_countries <- world[sel_area, ]
```

This creates a new simple feature data frame, `small_countries`, containing nations whose surface area is smaller than 10,000 sq km.

Note: there is no harm in keeping the geometry column because an operation on a {sf} object only changes the geometry when appropriate (e.g. by dissolving borders between adjacent polygons following aggregation). This means that the speed of operations with attribute data in {sf} objects is the same as with columns in a data frames.

The {base} R function `subset()` provides another way to get the same result.
```{r}
small_countries <- subset(world, 
                          area_km2 < 10000)
```

Importantly the {tidyverse} verbs can also be used on {sf} objects. The functions are `select()` and `filter()`.

CAUTION! The {dplyr} (and  {raster}) package has a function called `select()`. When using both packages in the same session, the function in the most recently attached package will be used, 'masking' the incumbent function. This will generate error messages containing text like: unable to find an inherited method for function 'select' for signature "sf". To avoid this error message, and prevent ambiguity, we use the long-form function name, prefixed by the package name and two colons `dplyr::select()`.

Recall that the `select()` function selects columns by name or position. For example, we can select only two columns, `name_long` and `pop`, with the following command.
```{r}
library(tidyverse)

world1 <- world %>%
  select(name_long, pop)
names(world1)
```

The result is a simple feature data frame with the geometry column.

The `select()` function lets us subset and rename columns at the same time.
```{r}
world %>%
  select(name_long, 
         population = pop)
```

The `pull()` function returns a single vector without the geometry.
```{r}
world %>%
  pull(pop)
```

The `filter()` function keeps only rows matching given criteria, e.g., only countries with a very high average life expectancy.
```{r}
world %>%
  filter(lifeExp > 82)
```

Aggregation summarizes a data frame by a grouping variable, typically an attribute column. An example of attribute aggregation is calculating the number of people per continent based on country-level data (one row per country). 

This is done with the `group_by()` and `summarize()` functions. 
```{r}
world %>%
  group_by(continent) %>%
  summarize(Population = sum(pop, na.rm = TRUE),
            nCountries = n())
```

The two columns in the resulting attribute table are `Population` and `nCountries`. The functions `sum()` and `n()` were the aggregating functions. 

The result is an simple feature data frame with a single row representing attributes of the world and the geometry as a single multi-polygon through the geometric union operator.

We can chain together functions to find the world's three most populous continents and the number of countries they contain.
```{r}
world %>% 
  select(pop, continent) %>% 
  group_by(continent) %>% 
  summarize(Population = sum(pop, na.rm = TRUE), 
            nCountries = n()) %>% 
  top_n(n = 3, wt = Population) 
```

If we want to create a new column based on already existing columns we use `mutate()` (or `transmute()`. For example, we want to calculate population density for each country. For this we need to divide a population column, here `pop`, by an area column, here `area_km2` with unit area in square kilometers. 
```{r}
world %>% 
  mutate(Population_Density = pop / area_km2)

world %>%
  transmute(Population_Density = pop / area_km2)
```

The latter skips all other existing columns except for the sticky geometry column.

## Creating geographic subsets

The {USAboundaries} package contains historical and contemporary boundaries for the United States with the data provided by the U.S. Census Bureau.
```{r}
if(!require(USAboundaries)) install.packages(pkgs = "USAboundaries", repos = "http://cran.us.r-project.org")

library(USAboundaries)
```

Individual states are extracted using the `us_states()` function. CAUTION: the function has the same name as the object `us_states` from the {spData} package. 

Here we use the argument `states =` to get only Kansas, then make a plot and check the native CRS.
```{r}
KS.sf <- us_states(states = "Kansas")

library(ggplot2)

ggplot(data = KS.sf) +
  geom_sf()

st_crs(KS.sf)
```

The polygon geometry includes the border and the area inside the border. The CRS has EPSG code of 4326.

Suppose we want to subset geographically rather than based on some attribute value. For example here we want to subset the tornado tracks by the Kansas polygon.

Import the tornado data.
```{r}
download.file(url = "http://myweb.fsu.edu/jelsner/temp/data/1950-2018-torn-aspath.zip",
              destfile = "1950-2018-torn-aspath.zip")
unzip("1950-2018-torn-aspath.zip")

Torn.sf <- st_read(dsn = "1950-2018-torn-aspath", 
                   layer = "1950-2018-torn-aspath")
```

The geometries are line strings representing the straight line track of each tornado. The CRS has EPSG code of 4326, same as the Kansas polygon.

Here we use the `st_intersection()` function to create a subset data frame of tornado data frame returning only the tornado tracks (or parts of the tornado track) that intersect the Kansas polygon. The first argument (`x =`) is the simple feature data frame that we want to subset and the second argument (`y =`) defines the geometry over which the subset occurs.
```{r}
KS_Torn.sf <- st_intersection(x = Torn.sf, 
                              y = KS.sf)
```

Then to visualize the result we make a plot.
```{r}
ggplot(data = KS.sf) +
  geom_sf() +
  geom_sf(data = KS_Torn.sf)
```

Note that no tornado track lies outside the state border. Line strings that lie outside the border are clipped at the border.

If we want the entire tornado track for all tornadoes that passed into (or through) the state, then we first use the geometric binary predict function `st_intersects()`. By specifying `sparse = FALSE` a matrix with a single column of `TRUE`s and `FALSE`s is returned. Here we use the piping operator to implicitly specify the `x =` argument as the `Torn.sf` data frame.
```{r}
Intersects <- Torn.sf %>%
  st_intersects(KS.sf, sparse = FALSE)

head(Intersects)
sum(Intersects)
```

Next we create a subset data frame from the original tornado data frame keeping only observations (rows) where `Interects` is TRUE.
```{r}
KS_Torn2.sf <- Torn.sf[Intersects, ]

ggplot(data = KS.sf) +
  geom_sf() +
  geom_sf(data = KS_Torn2.sf)
```

Suppose we want to determine the distance between the geographic center of the state and the middle of all the tornadoes. We start by computing the centroid for the state polygon and the centroid for the combined set of Kansas tornadoes.
```{r}
geocenterKS <- KS.sf %>%
  st_centroid()

centerKStornadoes <- KS_Torn.sf %>%
  st_combine() %>%
  st_centroid()
```

We then make a map and compute the distance in meters using the `st_distance()` function.
```{r}
ggplot(data = KS.sf) +
  geom_sf() +
  geom_sf(data = geocenterKS, col = "blue") +
  geom_sf(data = centerKStornadoes, col = "red")

geocenterKS %>%
  st_distance(centerKStornadoes)
```

More examples: https://www.jla-data.net/eng/spatial-aggregation/

## Mutating data frames with joins

Combining data from different sources based on a shared variable is a common operation. The {dplyr} package as part of the {tidyverse} group of packages has attribute join functions that following naming conventions used in database languages (like SQL).

Given two data frames labeled `x` and `y`, the join functions add columns _from y_ _to x_, matching rows based on the function name.

* `inner_join()`: includes all rows in `x` _and_ `y`
* `left_join()`: includes all rows in `x`
* `full_join()`: includes all rows in `x` _or_ `y`

Join functions work the same on data frames and on simple feature data frames objects. The most common type of attribute join on spatial data takes a simple feature data frame as the first argument and adds columns to it from a data a frame specified as the second argument.

For example, we combine data on coffee production with the `world` simple feature data frame. Coffee production by country is in the data frame called `coffee_data` from the {spData} package (see `?coffee_data` for details).
```{r}
glimpse(coffee_data)
```

It has 3 columns: `name_long` names major coffee-producing nations and `coffee_production_2016` and `coffee_production_2017` contain estimated values for coffee production in units of 60-kg bags per year.

Let us first select only the name and GDP (per person) from the `world` simple feature data frame.
```{r}
( world.sf <- world %>%
    select(name_long, gdpPercap) )
```

The `left_join()` function takes the data frame named by the argument `x =` and joins it to the data frame named by the argument `y =`.
```{r}
( world_coffee.sf <- left_join(x = world.sf, 
                               y = coffee_data) )
```

Because the two data frames share a common variable name (`name_long`) the join works without using the `by =` argument. The result is a simple feature data frame identical to the `world.sf` object but with two new variables on coffee production.
```{r}
names(world_coffee.sf)
```

For a join to work there must be at least one variable name in common.

Since the object listed in the `x =` argument is a simple feature data frame, the join function returns a simple feature data frame with the same number of rows (observations). 

Although there are only 47 rows of data in `coffee_data`, all 177 of the country records in `world.sf` are kept intact in `world_coffee.sf`. Rows in the first dataset with no match are assigned `NA` values for the new coffee production variables.

If we want to keep only countries that have a match in the key variable then we use `inner_join()`. Here we use the piping operator to implicitly specify the `x =` argument as the `world.sf` data frame.
```{r}
world.sf %>%
  inner_join(coffee_data)
```

We can join in the other direction, starting with a regular data frame and adding variables from a simple features object.

More information on attribute data operations: https://geocompr.robinlovelace.net/attr.html

## Interpolation using areal weighting

Areal-weighted interpolation estimates the value of some variable from a set of polygons to an overlapping but incongruent set of target polygons. For example, suppose we want demographic information given at the Census tract level to be estimated within the tornado damage path. Damage paths do not align with census tract boundaries so areal weighted interpolation is needed to get demographic estimates at the tornado level.

The function `st_interpolate_aw()` from the {sf} package performs areal-weighted interpolation of polygon data. As an example, consider the number of births by county in North Carolina in over the period 1970 through 1974 (`BIR74`).

The data are available as a shapefile as part of the {sf} package system file. We use the `st_read()` function together with the `system.file()` function to import the data to our current session. We then plot the geometry.
```{r}
nc.sf <- st_read(system.file("shape/nc.shp", 
                             package = "sf"))

ggplot(data = nc.sf) +
  geom_sf(mapping = aes(fill = BIR74))
```

Next we construct a 20 by 10 grid of polygons that overlaps the state using the `st_make_grid()` function. The function takes the bounding box from the `nc.sf` simple feature data frame and constructs a two-dimension grid using the dimensions specified with the `n =` argument.
```{r}
g.sfc <- st_make_grid(nc.sf, 
                      n = c(20, 10))

ggplot(g.sfc) +
  geom_sf(col = "red") +
  geom_sf(data = nc.sf, fill = "transparent")
```

The result is overlapping but incongruent sets of polygons as a `sfc` (simple feature column).

Then we use the `st_interpolate_aw()` function with the first argument a simple feature data frame for which we want to aggregate a particular variable and the argument `to =` to the set of polygons for which we want the variable to be aggregated. The name of the variable must be put in quotes inside the subset operator `[]`. The argument `extensive =` if `FALSE` (default) assumes the variable is spatially intensive (like population density) and the mean is preserved. 
```{r}
a1.sf <- st_interpolate_aw(nc.sf["BIR74"], 
                           to = g.sfc,
                           extensive = FALSE)
```

The result is a simple feature data frame with the same polygons geometry as the `sfc` grid and a single variable called (`BIR74`).

```{r}
( p1 <- ggplot(a1.sf) +  
    geom_sf(mapping = aes(fill = BIR74)) +
    scale_fill_continuous(limits = c(0, 18000)) +
    labs(title = "Intensive") )
```

We note that the average number of births across the state at the county level matches (roughly) the average number of births across the grid of polygons, but the sums do not match.
```{r}
mean(a1.sf$BIR74) / mean(nc.sf$BIR74)

sum(a1.sf$BIR74) / sum(nc.sf$BIR74)
```

An *intensive* variable is independent of the spatial units (e.g., population density, percentages); a variable that has been normalized in some fashion. An *extensive* variable depends on the spatial unit (e.g., population totals). Assuming a uniform population density, the number of people will depend on the size of the spatial area.

Since the number of births in each county is an extensive variable, we toggle the `extensive =` argument to `TRUE`.
```{r}
a2.sf <- st_interpolate_aw(nc.sf["BIR74"], 
                           to = g, 
                           extensive = TRUE)
( p2 <- ggplot(a2.sf) +  
    geom_sf(mapping = aes(fill = BIR74)) +
    scale_fill_continuous(limits = c(0, 18000)) +
    labs(title = "Extensive") )
```

In this case we preserve the total number of births across the domain. We verify this 'mass preservation' property (pycnophylactic property).
```{r}
sum(a2.sf$BIR74) / sum(nc.sf$BIR74)
```

Here we create a plot of both interpolations.
```{r}
library(patchwork)

p1 / p2
```

### Example: Tornadoes: people and property

Here we are interested in the number of housing units affected by tornadoes occurring in Florida 2014-2018. We begin by creating a polygon geometry for each tornado record.
```{r}
download.file(url = "http://myweb.fsu.edu/jelsner/temp/data/1950-2018-torn-aspath.zip",
              destfile = "1950-2018-torn-aspath.zip")
unzip("1950-2018-torn-aspath.zip")
```

Import the data, transform the native CRS to 3857 (pseudo-Mercator), and filter on `yr` (year) and `st` (state).
```{r}
#Torn.sf <- st_read(dsn = "1950-2018-torn-aspath", 
#                   layer = "1950-2018-torn-aspath") %>%
#  st_transform(crs = 3857)

FL_Torn.sf <- Torn.sf %>%
  filter(yr >= 2014, 
         st == "FL")
```

Next we change the geometries from line strings to polygons to represent the tornado path ('footprint'). The path width is given by the variable labeled `wid`. First we create new a new variable with the width in units of meters and then use the `st_buffer()` function with the `dist =` argument set to 1/2 the width.
```{r}
FL_Torn.sf <- FL_Torn.sf %>%
  mutate(Width = wid * .9144)

FL_TornPath.sf <- st_buffer(FL_Torn.sf,
                            dist = FL_Torn.sf$Width/2)
```

To visualize we plot the first tornado as a track and as a path.
```{r}
ggplot(FL_TornPath.sf[1, ]) + 
  geom_sf() +
  geom_sf(data = FL_Torn.sf[1, ], col = "red")
```

Next we get the census data using the `get_acs()` function from the {tidycensus} package. The package is an interface to the decennial US Census and American Community Survey APIs and the US Census Bureau's geographic boundary files. Functions return Census and ACS data as simple feature data frames for all Census geographies.
```{r}
if(!require(tidycensus)) install.packages(pkgs = "tidycensus", repos = "http://cran.us.r-project.org")

library(tidycensus)
```

The geometry is the tract level and the variable is the un-weighted sample housing units (B00002_001). We transform the CRS to that of the tornadoes.
```{r}
Census.sf <- get_acs(geography = "tract", 
                     variables = "B00002_001",
                     state = "FL",
                     year = 2018,
                     geometry = TRUE) %>%
  st_transform(crs = st_crs(FL_TornPath.sf))

head(Census.sf)
```

Finally we use the `st_interpolate_aw()` function
```{r}
awi.sf <- st_interpolate_aw(Census.sf["estimate"],
                            to = FL_TornPath.sf, 
                            extensive = TRUE)
head(awi.sf)
range(awi.sf$estimate, 
      na.rm = TRUE)
```

## Spatial data frames in the S4 class of data objects

The {sp} package has methods for working with spatial data. Several of the packages for analyzing and modeling spatial data we will use this semester depend on {sp}. Check out [sp](http://cran.r-project.org/web/packages/sp/index.html) and note the number of packages that depend on {sp} (reverse depends and reverse imports).

Install and load the package.
```{r}
library(sp)
```

Spatial objects from the {sp} package fall into two types: 1) spatial-only information (the topology). These include `SpatialPoints`, `SpatialLines`, `SpatialPolygons`, etc, and 2) extensions to these cases where attribute information is available and stored in a data frame. These include `SpatialPointsDataFrame`, `SpatialLinesDataFrame`, etc.

We use `as_Spatial()` to convert a simple feature data frame (as an S3 spatial object) to an S4 spatial object. Here we first transform the CRS back to WGS84.
```{r}
FL_Torn.sf <- FL_Torn.sf %>%
  st_transform(crs = 4326)

FL_Torn.sp <- FL_Torn.sf %>%
  as_Spatial()

class(FL_Torn.sp)
```

The result is a S4 spatial object of class `SpatialLinesDataFrame` called `FL_Torn.sp`. 

Information in S4 spatial objects is accessed through a slot name. The slot names are listed with the `slotNames()` function.
```{r}
slotNames(FL_Torn.sp)
```

The `data` slot contains the data frame, the `lines` slot contains the spatial geometries (in this case lines), the `bbox` slot is the boundary box and the `proj4string` slot is the CRS.

The object name followed by the `@` symbol allows access to the information in the slot. For example to see the first row of the data frame, and the corresponding first spatial geometry type
```{r}
FL_Torn.sp@data[1, ]

FL_Torn.sp@lines[1]
```

The `@` symbol is similar to the `$` symbol for regular data frames.

When using the `$` symbol on S4 spatial objects, we can access the data as a regular data frame. For example, to list the EF rating of all the tornadoes type
```{r}
FL_Torn.sp$mag
```

Selecting, retrieving, or replacing attributes in S4 spatial data frames is done with methods in {base} R package. For example `[]` is used to select rows and/or columns. To select `mag` of the 7th tornado type
```{r}
FL_Torn.sp$mag[7]
```

Other methods include: `plot`, `summary`,`dim` and `names` (operate on the data slot), `as.data.frame`, `as.matrix` and `image` (for gridded spatial data), and `length` (number of features).

CAUTION: we can't use the {dplyr} verbs on S4 data frames. To convert from an S4 spatial data frame to a simple feature data frame, use `st_as_sf()`.

The interface to the geometry engine-open source (GEOS) is through the {rgeos} package.
```{r}
library(rgeos)
```

When possible we will do our geo-computations on simple feature data frames. However, sometimes it is more convenient to perform geo-computations on S4 data frames. Also much of the current R code you might encounter doing GIS will be written with S4 objects.

Geo-computation should not be done on spatial objects with geographic coordinates (lat/lon). To see if the S4 spatial data frame is projected type
```{r}
is.projected(FL_Torn.sp)
```

To see the coordinate reference system (CRS) of the spatial data frame type
```{r}
FL_Torn.sp@proj4string
```

The CRS arguments include the projection (`+proj`), the datum (`+datum`), and the ellipsoid (`+ellps`). Here we see the projection is `longlat` indicating that this is a geographic CRS (not projected).

To create a projected `SpatialLinesDataFrame` we use the `spTransform()` function. The first argument is the original spatial data frame and the second argument is the coordinate reference system as a character string.
```{r}
FL_TornP.sp <- FL_Torn.sp %>%
  spTransform(CRS = CRS("+proj=merc +ellps=GRS80 +units=m"))
is.projected(FL_TornP.sp)
```

The CRS character string is in the open GIS standard format. It includes the projection type (here Mercator), the ellipsoid shape (here GRS80) and the spatial units (here meters).
```{r}
FL_TornP.sp@proj4string
```

We now have two copies of our `SpatialLinesDataFrame` object (unprojected `sldf` and projected `sldfP`).

We perform geo-computation on the projected spatial data frame using functions from the {rgeos} package. 

Computations can be done across all features (e.g., all tornado reports together) or feature by feature (`byid = TRUE`). For example, to the `gEnvelope()` function computes the rectangular bounding box surrounding all the features.
```{r}
box <- gEnvelope(FL_TornP.sp)
class(box)
```

The assigned object `box` is of class `SpatialPolygons`. It contains a single polygon rectangle. The `byid = FALSE` is the default. There are no attributes.

Plot the box and the tornadoes using {base} R.
```{r}
plot(box)
plot(sldfP, add = TRUE)
```

The `plot()` method applied to an S4 spatial object plots the geometries without the attributes.