---
title: "Lesson 8"
author: "James B. Elsner"
date: "February 3, 2021"
output:
  html_document: null
editor_options:
  chunk_output_type: console
---

## Working with Rasters

The _raster data model_ divides geographic space into a grid of cells of constant size (resolution) and we use classes from the {raster} package to work with raster data.

A raster in R is a data structure that divides space into rectangles called 'cells' (or 'pixels'). Each cell has an attribute value.

The {raster} package has functions for creating, reading, manipulating, and writing raster data as S4 objects and functions for raster manipulation common in GIS.
```{r}
library(raster)
```

An S4 `RasterLayer` object (raster) is one variable (called a 'layer' or a 'band'). The object includes the number of columns and rows, the coordinates of its spatial extent (bounding box), and the coordinate reference system (CRS). 

A raster can also store information about the external file from where it came.

The package has two classes for data with more than one variable associated with each cell (multi-layer data) the `RasterStack` and the `RasterBrick`. A `RasterBrick` can only be linked to a single (multi-layer) file. A `RasterStack` can be formed from separate files. Otherwise they are the same.

Creating raster objects

The `raster()` function creates a raster with a geographic (longitude/latitude) CRS and a 1 by 1 degree grid of cells across the globe.
```{r}
r <- raster()
r
```

Arguments including `xmin`, `nrow`, `ncol`, and `crs` are used to change these default settings. The CRS is written as a proj4string.

The default raster layer is in geographic coordinates spanning the globe at one-degree resolution in the north-south and the east-west directions.

We know the raster object is an S4 class because it has slots (e.g., `@data`).
```{r}
str(r)
```

The slot names are retrieved with
```{r}
slotNames(r)
```

To create an alternative raster with 36 longitudes -100 and 0 degrees East longitude and 18 latitudes between the equator and 50 degrees N latitude we specify the number of columns, the number of rows and the extent as follows.
```{r}
r <- raster(ncol = 36, nrow = 18, 
            xmn = -100, xmx = 0, 
            ymn = 0, ymx = 50)
r
res(r)
```

This results in raster with cell resolution of 2.7 degrees of longitude and 2.7 degrees of latitude.

The parameters can be changed after the raster is created. Here we change the resolution to exactly 3 degrees. This changes the number of rows and columns.
```{r}
res(r) <- 3
ncol(r)
nrow(r)
```

Here we change the number of columns to 18. This changes the resolution to 5.5 degrees in the east-west direction but keeps the resolution at 3 degrees in the north-south direction.
```{r}
ncol(r) <- 18
res(r)
```

The raster object `r` is a template with no values in the cells. By default it will have an extent that spans the globe.
```{r}
r <- raster(ncol = 10, nrow = 10)
ncell(r)
hasValues(r)
```

Here there are 100 cells in a 10 by 10 empty raster. We use the `values()` function to place values in the cells. The function is specified on the left-hand side of the assignment operator. First we assign to a vector of length `ncell(r)` random numbers from a uniform distribution with the `runif()` function. The default is that the random numbers are between 0 and 1.
```{r}
v <- runif(ncell(r))
head(v)
values(r) <- v
head(r)
```

The cells are arranged in lexicographical order (upper left to lower right) and the cells are populated with the values in the vector in this order.

The `plot()` method creates a choropleth map of the values in cells.
```{r}
plot(r)
```

The default CRS is geographic.
```{r}
projection(r)
```

To project the raster use the function `projectRaster()`. Projections are performed using the `PROJ4` protocol accessed through the {rgdal} package (same as with {sf} and {sp} objects).

We can also use the `setValues()` function to place values in the cells. Here we create a new raster layer with cell numbers as values using the `setValues()` function to place the numbers in the cells.
```{r}
r <- raster(xmn = -110, xmx = -90, 
            ymn = 40, ymx = 60, 
            ncols = 10, nrows = 10)
r <- setValues(r, 1:ncell(r))
projection(r)
plot(r)
```

The numbers increase from top right to bottom left.

Next we create a projected raster.
```{r}
rp <- projectRaster(r, 
                    crs = "+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m")
plot(rp)
```

The projection is performed using bi-linear interpolation (default). In the case where the values are categorical we use `method = "ngb"` for nearest neighbor.

The function `rasterFromXYZ()` is used to create a raster from a data frame where two of the columns are spatial coordinates listed in an array format.

For example, first create a data frame.
```{r}
x <- seq(0, 10, length.out = 11)
y <- seq(-1, 1, length.out = 11)
df <- expand.grid(x = x, y = y)
head(df)
df$v <- rnorm(nrow(df))
df
```

The first two columns are the spatial locations in an array format and the third is an attribute.

Use the `rasterFromXYZ()` function to convert the data frame to a raster.
```{r}
dfr <- rasterFromXYZ(df)        
plot(dfr)
```

Note: this only works if the spatial coordinates are arranged in the format of an array.

The `raster()` function imports data with functions from the {rgdal} package. Supported formats include `GeoTIFF`, `ESRI`, `ENVI`, and `ERDAS`. Most formats that can import rasters can also be used to exporting rasters. 

Consider the `Meuse` dataset (taken from the {sp} package), using a file in the native 'raster- file' format:
```{r}
f <- system.file("external/test.grd", 
                 package = "raster")
r <- raster(f)
filename(r)
```

Do the cells contain values? Is the raster stored in memory? Create a plot.
```{r}
hasValues(r)
inMemory(r)
plot(r, main = "Raster layer from file")
```

Note the raster layer is a rectangle of cells with values. Values that are coded as `NA` are not plotted.
```{r}
head(r)
```

We can combine raster layers into stacks and bricks. A stack (and a brick) is a collection of raster layers having the same spatial extent and resolution. 

A brick is typically imported from a multi-layer (band) external file. They can also exist entirely in memory. A raster brick can only point to a single external file.

For example, create three rasters and assign random values to the cells.
```{r}
r1 <- r2 <- r3 <- raster(nrow = 10, ncol = 10)
values(r1) <- runif(ncell(r1))
values(r2) <- runif(ncell(r2))
values(r3) <- runif(ncell(r3))
```

Then combine the rasters into a stack with `stack()` (or into a brick with `brick()`).
```{r}
s <- stack(r1, r2, r3)
s
nlayers(s)
plot(s)
```

So each attribute in a raster stack (or brick) is a layer.

Here we import a raster brick from a file.
```{r}
f <- system.file("external/rlogo.grd", 
                 package = "raster")
b <- brick(f)
b
plot(b)
```

Suppose we only want a single layer (e.g., one attribute). We extract a raster layer from a brick or stack with the `layer =` or `band =` arguments.
```{r}
r <- raster(b, layer = 2)
plot(r)
```

Most base R functions (`+`, `*`, `round()`, `ceiling()`, `log()`, etc) work on raster objects. Operations are done on all cells at once.

Here we place the numbers from 1 to 100 sequentially in the cells, then add 100 to these values and take the square root.
```{r}
r <- raster(ncol = 10, nrow = 10)
values(r) <- 1:ncell(r)
s <- r + 100
s <- sqrt(s)
plot(s)
```

Here we replace the cell values with random uniform numbers between 0 and 1. Then round to the nearest integer and add one.
```{r}
r <- setValues(r, runif(ncell(r)))
r <- round(r)
r <- r + 1
plot(r)
```

Replace only certain values with the subset function `[]`.
```{r}
r <- raster(xmn = -90, xmx = 90, ymn = -30, ymx = 30)
values(r) <- rnorm(ncell(r))
plot(r)
s <- raster(xmn = -60, xmx = 60, ymn = -10, ymx = 10)
r[s] <- 0
plot(r)
r[r > 2] <- 0
plot(r)
```

Raster objects with the same resolution and origin can be combined.

Summary functions (`min`, `max`, `mean`, etc) return a raster object. They are useful when we have more than one raster.

Here we create four rasters each with a different set of values from a random normal distribution. We then create a raster containing the average value by cell in rasters one through four. We also create a raster containing the sum of the values by cell in rasters one and two.
```{r}
r <- raster(ncol = 5, nrow = 5)
r1 <- setValues(r, rnorm(ncell(r)))
r2 <- setValues(r, rnorm(ncell(r)))
r3 <- setValues(r, rnorm(ncell(r)))
r4 <- setValues(r, rnorm(ncell(r)))
a <- mean(r1, r2, r3, r4)
plot(a)
b <- sum(r1, r2)
plot(b)
```

To get summary statistics across all values _within_ a particular raster we use the `cellStats()` function.
```{r}
cellStats(r1, stat = 'mean')
cellStats(b, stat = 'sum')
```

## Geocomputation on rasters

The `crop()` function takes a geographic subset of a larger raster object. A raster is cropped by providing an extent object or other spatial object from which an extent can be extracted (objects from classes deriving from raster and from spatial in the {sp} package). 

The function `drawExtent()` is used to visually see the new extent (bounding box) that is given to the `crop()` function.

The `trim()` function crops a raster layer by removing the outer rows and columns that only contain `NA` values. The `extend()` function adds new rows and/or columns with `NA` values.

The `extract()` function retrieves values from a raster object at the locations of other spatial data.

The `merge()` function combines two or more objects into a single object. The input objects must have the same resolution and origin (such that their cells fit into a single larger raster). If this is not the case, first adjust one of the objects with the functions `aggregate()` or `resample()`.

The `aggregate()` and `disaggregate()` functions change the resolution (cell size) of a raster object.
```{r}
r <- raster()
r[] <- 1:ncell(r)
ra <- aggregate(r, 10)
```

Here we crop the raster into two pieces and then merge them into one with the `merge()` function. The function has an argument that allows us to export to `test.grd`.
```{r}
r1 <- crop(r, extent(-180, 0, 0, 30)) 
r2 <- crop(r, extent(-10, 180, -20, 10))
m <- merge(r1, r2, 
           filename = 'test.grd', 
           overwrite = TRUE)
plot(m)
```

Other formats for saving the raster (e.g., `geoTIFF`) are available (see `writeRaster()` for more options). 

The `flip()` function flips the data (reverse order) in the horizontal or vertical direction---typically to correct for a 'communication problem' between different R packages or a misinterpreted file. The `rotate()` function rotates longitude/latitude rasters that have longitudes from 0 to 360 degrees (often used by climatologists) to the standard -180 to 180 degrees system. With the `t()` function you can rotate a raster object 90 degrees.

Point-to-raster conversion is often done to analyze point-pattern data. For example to count the number of distinct species (represented by point observations) that occur in each raster cell. The `rasterize()` function takes a raster object to set the spatial extent and resolution, and a function to determine how to summarize the points (or an attribute of each point) by cell.

Polygon to raster conversion is typically done to create a `RasterLayer` that can act as a mask, i.e. to set to `NA` a set of cells of a raster object, or to summarize values on a raster by zone. For example a country polygon is transferred to a raster that is then used to set all the cells outside that country to `NA`; whereas polygons representing administrative regions such as states can be transferred to a raster to summarize raster values by region.

It is also possible to convert the values of a raster layer to points or polygons, using `rasterToPoints()` and `rasterToPolygons()`. These functions return values only for cells that are not missing (`NA`).

### Example: Tornado counts by raster

https://rpubs.com/jelsner/tornadoRisk_longTermView
https://rpubs.com/jelsner/tornadoRisk_shortTermView

```{r}
library(sf)
Torn.sf <- st_read(dsn = "Data/1950-2018-torn-initpoint") %>%
  filter(yr >= 2003)
st_crs(Torn.sf)
```

Next set the raster domain slightly larger than the bounding box and assign a resolution of one degree in longitude and one degree in latitude. Check the extent of the raster with the `extent()` function.
```{r}
library(raster)
frame <- raster(xmn = -106, xmx = -67, ymn = 24, ymx = 50)
res(frame) <- .5
extent(frame)
```

Use the `rasterize()` function to count the number of times each raster cell contains a tornado genesis location. The first argument is the spatial data frame and the second is the raster without values. The argument `field =` specifies a column name in the spatial data frame (here just an identifier) and the argument `fun =` specifies what to do (here simply count the unique instances of the field in each cell). Raster cells without tornadoes are given a value of 0 based on the `background =` argument.

```{r}
t0 <- Sys.time()
Torn.r <- rasterize(Torn.sf, frame, 
                   field = "om", 
                   fun = "count",
                   background = 0)
Sys.time() - t0
class(Torn.r)
dim(Torn.r)
```

This took 5 minutes.

The result is a raster layer. The number of tornadoes occurring in each cell are the values.
```{r}
values(Torn.r)[1:200]
```

We make a quick map with the `plot()` method.
```{r}
plot(Torn.r)
```

It looks right. Some cells across the Plains and the South have quite a few tornadoes others not as many.

A spatial statistic indicating how similar values in neighboring cells tend to be is Moran I. It is implemented on rasters with the `Moran()` function. 

```{r}
Moran(Torn.r)
```

Moran I is a global measure of clustering (high values near high values and low values near low values). Values range from -1 to +1 where positive values indicate clustering and negative values indicate regularity (e.g., chessboard).

The estimate of .84 indicates a high level of tornado clustering at this scale. Under the null hypothesis of no spatial autocorrelation the expected value for Moran I is close to zero [-1/(n-1), where n is the number of cells].

With raster data the neighborhood definition is constant across the study region.

Clusters at a local level can be found using a local indicator of spatial autocorrelation. One such indicator is local Moran I, which is computed at each cell (using the `MoranLocal()` function) so the result is a raster.
```{r}
Torn_lmi.r <- MoranLocal(Torn.r)
plot(Torn_lmi.r)
```

Here we can more clearly delineate the hot spots of tornadoes over the south-central Plains.

```{r}
library(tmap)
library(USAboundaries)
States.sf <- us_states()
tm_shape(Torn_lmi.r) +
  tm_raster(n = 10) +
tm_shape(States.sf) +
  tm_borders()
```

Local Getis Ord
```{r}
Torn.sp <- rasterToPolygons(Torn.r)
nbs <- poly2nb(Torn.sp)
wts <- nb2listw(nbs)
localG.r <- frame
values(localG.r) <- as.vector(localG(Torn.sp$layer,
                              listw = wts))
tm_shape(localG.r) +
  tm_raster(n = 10) +
tm_shape(States.sf) +
  tm_borders()
localGclumps.r <- as.integer(localG.r > 3)
plot(localGclumps.r)
rc <- clump(localGclumps.r)
freq(rc)
plot(rc)
tm_shape(rc) +
  tm_raster(n = 8) +
tm_shape(States.sf) +
  tm_borders()
```

Focal (neighborhood) functions

The functions: `focal()`, `focalFilter()`, `focalNA()` compute statistics in a neighborhood of cells around a focal cell, putting the result in the focal cell of an output raster. 

With `focal()`, the neighborhood can only be a rectangle. With `focalFilter()`, the neighborhood is a user-defined a matrix of weights and could approximate any shape by giving some cells zero weight. The `focalNA()` function only computes new values for cells that are `NA` in the input raster.

The `distance()` function computes the shortest distance to cells that are not NA. The `pointDistance()` function computes the shortest distance to any point in a set of points. 

The `gridDistance()` function computes the distance when following grid cells that can be traversed (e.g. excluding water bodies). The `direction()` function computes the direction towards (or from) the nearest cell that is not `NA`. The `adjacency()` function determines which cells are adjacent to other cells, and the `pointDistance()` function computes distance between points. 

Summary functions

The function `cellStats()` computes summary statistics on a raster. For example:
```{r}
cellStats(Tor_r, mean)
cellStats(Tor_r, max)
freq(Tor_r)
```

Use `zonal()` to summarize a raster object using zones (areas with the same integer number) defined in a `RasterLayer` and `crosstab()` to cross-tabulate two `RasterLayer` objects.

Convert `raster` to polygons. 
```{r}
spdf <- rasterToPolygons(Tor_r)
```

Convert the `SpatialPolygonsDataFrame` to a simple features data frame.
```{r}
sfdf <- st_as_sf(spdf)
```

## The S4 spatial class

Install and load the packages.
```{r}
library(sp)
library(sf)
```

Functions in these packages link to software libraries outside of R. For example GDAL is a set of libraries for reading and writing geospatial data and PROJ is a set of libraries for performing conversions between cartographic projections.

The {sp} package has methods for working with 'vector' spatial data. Note: 'vector' is in quotes because this is different than vector as a data type.

Several of the packages for analyzing and modeling spatial data we will use this semester depend on {sp}. Check out [sp](http://cran.r-project.org/web/packages/sp/index.html) and note the number of packages that depend on {sp} (reverse depends and reverse imports).

Spatial objects from the {sp} package fall into two types: 1) spatial-only information (the topology). These include `SpatialPoints`, `SpatialLines`, `SpatialPolygons`, etc, and 2) extensions to these cases where attribute information is available and stored in a data frame. These include `SpatialPointsDataFrame`, `SpatialLinesDataFrame`, etc.

As an example, we download the shapefile from the SPC (if it's not already available in your working directory) and use `st_read()` from the {sf} package keeping only tornadoes since 2007. Note that we use the `filter()` function and the piping operator from the {dplyr} package as part of the {tidyverse} group of packages.
```{r}
library(tidyverse)
sfdf <- st_read(dsn = "1950-2018-torn-aspath") %>%
  filter(yr >= 2007)
class(sfdf)
```

The object `sfdf` is of class `sf` and `data.frame` (simple feature data frame).

Note: `st_read()` is the same as `read_sf()` that we used in the last two lessons except the attribute table is a data frame rather than a tabled data frame (tibble).

To convert `sfdf` with class `sf` as an S3 object to an S4 spatial object use `as(sfdf, "Spatial")`. 
```{r}
sldf <- as(sfdf, "Spatial")
```

The spatial object `sldf` is a S4 spatial object of class `SpatialLinesDataFrame`. Information contained in S4 spatial objects is accessed through a slot name. For example, `x@coords` contains the coordinates of a S4 spatial object `x` and `x@data` contains the attribute table as a data frame.
```{r}
glimpse(sldf@data)
```

The `@` symbol is similar to the `$` symbol for regular data frames.

Slots in a `SpatialLinesDataFrame` include `data`, `lines`, `bbox`, and `proj4string`.
```{r}
slotNames(sldf)
```

Selecting, retrieving, or replacing attributes in S4 spatial data frames is done with methods in {base} R. For example `[]` is used to select rows and/or columns. To select `mag` of the 7th tornado type
```{r}
sldf$mag[7]
```

Other methods include: `plot`, `summary`,`dim` and `names` (operate on the data slot), `as.data.frame`, `as.matrix` and `image` (for gridded spatial data), and `length` (number of features).

CAUTION: we can't use the {dplyr} verbs on S4 data frames. To convert from an S4 spatial data frame to a simple feature data frame, use `st_as_sf()`.

The interface to the geometry engine-open source (GEOS) is through the {rgeos} package.
```{r}
library(rgeos)
```

When possible we will do our geocomputations on simple feature data frames. However, sometimes it is more convenient to perform geocomputations on S4 data frames. Also much of the current R code you might encounter doing GIS will be written with S4 objects.

Geocomputation should not be done on spatial objects with geographic coordinates (lat/lon). To see if the S4 spatial data frame is projected type
```{r}
is.projected(sldf)
```

To see the coordinate reference system (CRS) of the spatial data frame type
```{r}
sldf@proj4string
```

The CRS arguments include the projection (`+proj`), the datum (`+datum`), and the ellipsoid (`+ellps`). Here we see the projection is `longlat` indicating that this is a geographic CRS (not projected).

To create a projected `SpatialLinesDataFrame` we use the `spTransform()` function. The first argument is the original spatial data frame and the second argument is the coordinate reference system as a character string.
```{r}
sldfP <- spTransform(sldf, 
                     CRS = CRS("+proj=merc +ellps=GRS80 +units=m"))
is.projected(sldfP)
```

The CRS character string is in the open GIS standard format. It includes the projection type (here Mercator), the ellipsoid shape (here GRS80) and the spatial units (here meters).
```{r}
sldfP@proj4string
```

We now have two copies of our `SpatialLinesDataFrame` object (unprojected `sldf` and projected `sldfP`).

We perform geocomputation on the projected spatial data frame using functions from the {rgeos} package. 

Computations can be done across all features (e.g., all tornado reports together) or feature by feature (`byid = TRUE`). For example, to the `gEnvelope()` function computes the rectangular bounding box surrounding all the features.
```{r}
library(rgeos)
box <- gEnvelope(sldfP)
class(box)
```

The assigned object `box` is of class `SpatialPolygons`. It contains a single polygon rectangle. The `byid = FALSE` is the default. There are no attributes.

Plot the box and the tornadoes using {base} R.
```{r}
plot(box)
plot(sldfP, add = TRUE)
```

Note that the `plot()` method applied to an S4 spatial object plots the geometries without the attributes.

Another example: Consider the ESRI shapefile containing police expenditure data from Mississippi. The data are on my Web site and are downloaded and imported as follows.
```{r}
download.file("http://myweb.fsu.edu/jelsner/temp/data/police.zip",
              "police.zip")
unzip("police.zip")
sfdf <- st_read(dsn = "police")
```

Create an S4 spatial object from the simple feature object.
```{r}
spdf <- as(sfdf, "Spatial")
```

Note that the proj4string is specified as `NA` (missing). We know these data have a geographic CRS so we assign it as follows.
```{r}
proj4string(spdf) <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
```

The `plot()` method plots the polygons. First using the native geographic coordinates then using projected coordinates. We set up the side-by-side plots using the `par()` function.
```{r}
par(mfrow = c(1, 2))
plot(spdf)
spdfP <- spTransform(spdf, 
                     CRS = CRS("+proj=lcc +lat_1=60 +lat_2=30 +lon_0=-80 +units=km"))
plot(spdfP)
par(mfrow = c(1, 1))
```

Note: Here the projection is a Lambert conformal conic with secant latitudes at 30 and 60N and centered at 80W longitude.

By including the `byid = TRUE` argument in the `gEnvelope()` function, we create a spatial polygon object with 82 rectangles.
```{r}
boxes <- gEnvelope(spdfP, 
                   byid = TRUE)
plot(boxes)
```

The `gCentroid()` function computes the geometric center of the spatial object and returns a S4 spatial object of class `SpatialPoints`.
```{r}
centers <- gCentroid(spdfP, 
                     byid = TRUE)
class(centers)
plot(centers)
```

The function `gArea()` returns the geographical area (in square kilometers) of the geometries.
```{r}
areas <- gArea(spdfP, 
               byid = TRUE) %>%
   glimpse()
```

The output here is a numeric vector of length 82 listing the area of each county (in square kilometers).

Q: How would you determine the area of the entire state?

The `gContains()` function tests whether one geometry contains or is contained within another geometry. For example, which county contains the geographic center of the state? First determine the center with the `gCentroid()` function then determine which county contains it using the `gContain()` function.
```{r}
center <- gCentroid(spdfP)
countyCenter <- gContains(spdfP, 
                          center, 
                          byid = TRUE)
countyCenter
```

The result is a matrix containing all values equal to `FALSE` except for the county containing the geographic center.

To see this we use the `plot()` method. First the county boundaries then the center point as a red cross.
```{r, eval=FALSE}
plot(spdfP)
plot(center, 
     add = TRUE,
     col = "red")
```

Suppose we want to subset the center county making it it's own `SpatialPolygonsDataFrame`. We first turn the `matrix` object `countyCenter` into a vector then use the `[]` operator on `spdfP`.
```{r, eval=FALSE}
centerCounty <- spdfP[as.vector(countyCenter), ]
plot(spdfP)
plot(centerCounty, 
     col = "red", 
     add = TRUE)
```

The `gBuffer()` function expands the given geometry to include the area within the specified width with specific styling options. Here we create a buffer around the state at a distance of 100 km.
```{r, eval=FALSE}
largerState <- gBuffer(spdfP, 
                       width = 100)
plot(largerState)
plot(spdfP, 
     add = TRUE)
```

The output from `gBuffer()` is a `SpatialPolyons` object.

There are many more functions for geocomputation on S4 spatial data frames. The reference manual is available here https://cran.r-project.org/web/packages/rgeos/rgeos.pdf

Most of the time there is no need to create a spatial data frame since it will be imported as such. However it's helpful to understand how spatial data are constructed and stored.

For example, here we import a data frame the contains information on the location of the CRAN sites in 2007.
```{r}
df <- read.table(file = "http://myweb.fsu.edu/jelsner/temp/data/CRAN051001a.txt",
                 header = TRUE)
head(df)
```

Note here I use the `read.table()` function from base R. It is very similar to the `read_table()` function from the {readr} package but the default requires you to specify whether the first row of the file contains column names (`header = TRUE`).

Each row is a location. The location includes the name of the location and spatial coordinates. 

Here we create a spatial points data frame using the `coordinates()` function (from the {sp} package). We first assign to the object `spdf` the original data frame. We then specify what columns in `spdf` we want as the coordinates. Here use the columns labeled `long` and `lat`.
```{r}
spdf <- df
coordinates(spdf) <- c("long", "lat")
```

Note: Unlike most functions, the `coordinates()` is on the left side of the assignment operator.

```{r}
head(spdf)
head(spdf@data)
```

The columns `long` and `lat` are moved to the `coords` slot of the now spatial points data frame.

```{r}
head(slot(spdf, "coords"))
```

The `proj4string` slot is coded as `NA` indicating that there is no coordinate reference system (CRS). We see that with the `proj4string()` function or with `spdf@proj4string`.
```{r}
proj4string(spdf)
spdf@proj4string
```

Since the coordinates are longitude and latitude we assign a geographic CRS. We do that by first using the `CRS()` function and specifying a PROJ character string. We then assign this to the spatial points data frame with the `proj4string()` function.
```{r}
llCRS <- CRS("+proj=longlat +ellps=WGS84")
proj4string(spdf) <- llCRS
proj4string(spdf)
```

We can speak of a geographic CRS (model for shape of the earth plus lat/lon) or a projected CRS (model for shape of Earth plus a specific geometric model for projecting to a flat surface).
```{r}
is.projected(spdf)
```

Once the data has a CRS, it can be re-projected using the `spTransform()` function in the {rgdal} package.

The `spplot()` method

The easiest way to make a thematic map with an S4 spatial data frame is with the `spplot()` method. The first argument in the `spplot()` function is the spatial data frame object and the second argument specifies what column to use to fill or color.

For example, returning to the police expenditure spatial polygons data frame (`spdfP`) we create a map of police expenditures by county. The expendures are in the column labeled `POLICE` so we specify this column name with the argument `zcol = "POLICE"`.
```{r}
spplot(spdfP, 
       zcol = "POLICE")
```

The result is a choropleth map indicating police expenditures with a default color ramp from dark blue (indicating low expenditure) to yellow (indicating high expenditure).

While easy to apply the default settings on this method fail to produce a good map. We can improve things but it requires some trial-and-error.

For example, to improve the color ramp. We first specify a range of values using the `seq()` function then a set of 6 colors using the `brewer.pal()` function from the {RColorBrewer} package. We determine the range with the `range()` function. 

We specify the color palette to be 6 shades of green. We then add the arguments `col.regions =` and `at =` in the `spplot()` function call.
```{r}
library(RColorBrewer)
range(spdfP$POLICE)
rng <- seq(0, 12000, 2000)
cls <- brewer.pal(6, "Greens")
spplot(spdfP, 
       zcol = "POLICE", 
       col.regions = cls, 
       at = rng)
```

## Space-time data

See stars.Rmd in space-time projects.

## Spatial networks

See https://github.com/luukvdmeer/sfnetworks

## Notes on coordinate reference systems

See also https://gist.github.com/DavZim
```{r}
library(tidyverse)
library(sf)
library(spData)
library(gganimate)
data(world)

# see also: https://proj.org/operations/projections/index.html
projs <- list(
  "Mercator" = "+proj=merc",
  "WGS 84" = "+proj=longlat",
  "Robinson" = "+proj=robin",
  "Compact Miller" = "+proj=comill",
  "Eckert I" = "+proj=eck1",
  "Eckert II" = "+proj=eck2",
  "Eckert III" = "+proj=eck3",
  "Eckert IV" = "+proj=eck4",
  "Mollweide" = "+proj=moll", 
  "Azimuth Equidistant" = "+proj=aeqd",
  "Lambert Equal Area" = "+proj=laea",
  "Adams World in a Square 2" = "+proj=adams_ws2",
  "Sinusoidal (Sanson-Flamsteed)" = "+proj=sinu",
  "Interrupted Goode Homolosine" = "+proj=igh"
)

dd <- map_dfr(projs, function(p) {
  d <- world %>% 
    select(iso_a2, name_long, continent, geom) %>% 
    mutate(projection = p, L1 = 1:n()) %>% 
    st_transform(p)
  
  dd <- left_join(
    st_coordinates(d) %>% as_tibble(), 
    d %>% as_tibble() %>% select(-geom), 
    by = "L1"
  )
  
  res <- dd %>% 
    select(x = X, y = Y, everything()) %>% 
    mutate(id = paste0(L1, L2, L3)) %>% 
    mutate(x_orig = x, y_orig = y,
           x = (x - min(x)) / (max(x) - min(x)),
           y = (y - min(y)) / (max(y) - min(y)))
  
  res
}) %>% 
  mutate(projection = factor(projection, levels = unlist(projs)))

anim <- ggplot(dd, aes(x = x, y = y, group = id)) + 
  geom_polygon(fill = "black") +
  transition_states(projection) +
  ease_aes("cubic-in-out") +
  labs(title = "The World in '{names(projs)[projs == closest_state]}' Projektion",
       subtitle = "Projection: '{closest_state}'") +
  theme_minimal() +
  theme(axis.title=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank(), 
        panel.grid=element_blank(),
        plot.background=element_rect(fill = "white"))

anim_save("images/projections.gif", anim, res = 200, width = 1000, height = 1000)
```

CRS provide a standardized way of describing locations. Many different CRS are used to describe geographic data. The CRS that is chosen depends on when the data was collected, the geographic extent of the data, the purpose of the data, etc.

When data with different CRS are combined it is important to transform them to a common CRS so they align with one another. This is similar to making sure that units are the same when measuring volume or distances. 

In S4 spatial objects, CRS information is available in the `proj4string` slot.
```{r}
proj4string(sldf)
```

Information is given as a character string that includes the projection (here `+proj=longlat`), the datum (here `+datum=WGS84 +towgs84=0,0,0`), and the ellipsoid (here `+ellps=WGS84`). The syntax uses the PROJ standard. Various options are listed with the `projInfo()` function from the {rgdal} package.
```{r}
library(rgdal)
head(projInfo(type = "proj"))
projInfo(type = "datum")
head(projInfo(type = "ellps"))
```

The ellipsoid describes the shape of the Earth and the datum provides the information needed to anchor the abstract coordinates to the Earth. The datum defines an origin point of the coordinate axes and defines the direction of the axes. 

The datum always specifies the ellipsoid, but the ellipsoid does not specify the datum. Datums are based on specific ellipsoids and sometimes have the same name as the ellipsoid. 
A CRS can be referenced by its EPSG code (e.g., `epsg:4121`). The EPSG is a structured dataset of CRSs originally compiled by the European Petroleum Survey Group (EPSG). Details of a particular EPSG code is obtained by
```{r}
CRS("+init=epsg:4326")
```

EPSG codes for commonly used CRSs include: 

* Geographic

- WGS84 (EPSG:4326) Used by organizations that provide GIS data for the entire globe. Used by Google Earth.
- NAD83 (EPSG:4269) Used by U.S. federal agencies.

* Projected

- Mercator (EPSG:3857) Mercator, tiles from Google Maps, Open Street Maps, Stamen Maps
- UTM, Zone 10 (EPSG:32610) Pacific Northwest

When `readOGR()` and `st_read()` are used to load spatial data, the CRS information is included as part of the spatial object.
```{r}
proj4string(sldf)
attr(sfdf$geometry, "crs")$proj4string
```

To assign a known CRS to a S4 spatial object `x` type either:
```{r, eval=FALSE}
proj4string(x) <- CRS("+init=epsg:28992")
proj4string(x) <- CRS("+proj=utm +zone=10 +datum=WGS84")
```

CAUTION: Assigning a CRS does not re-project the geometry. Also, this is only for S4 spatial data. To transform from one CRS to another use the `spTransform` function from the {rgdal} package. For example, type either:
```{r, eval=FALSE}
xT <- spTransform(x, CRS("+init=epsg:4238"))
xT <- spTransform(x, proj4string(z))
```

Here `z` is a spatial data with a valid CRS.

An overview of CRSs is available here https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/OverviewCoordinateReferenceSystems.pdf

Note: NOAAâ€™s National Geodetic Survey is currently working on the modernization of the National Spatial Reference System (NSRS), which will replace the North American Datum of 1983 (NAD83) and the North American Vertical Datum of 1988 (NAVD88) with a new geometric reference frame and geopotential datum in 2022.