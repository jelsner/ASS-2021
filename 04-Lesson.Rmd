---
title: "Lesson 4"
author: "James B. Elsner"
date: "January 20, 2021"
output:
  html_document: null
editor_options:
  chunk_output_type: console
---

**"Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread."** --- Hadley Wickham

To help you better manage this course: I will try to post an "early draft" of the lesson notes on GitHub (https://github.com/jelsner/ASS-2021). The final versions, which will be available about 30 minutes before class time, will be posted on GitHub and on Canvas. I will try to have drafts of the next two lessons posted on GitHub sometime during the weekend before. You can check out all the lessons (compiled into Chapters using bookdown) from last Springs ASS course here https://github.com/jelsner/Applied_Spatial_Statistics. Also, if you need more time with a particular assignment, don't hesitate to contact me.

## Working with data frames using functions from the {tidyverse} set of packages

Data wrangling (data munging) is the process of transforming data from one format into another making it easier to summarize the information. 

The {dplyr} package (part of the {tidyverse} set of packages) includes functions that wrangle data frames in an easy-to-remember and logical way. The functions perform operations on data frames and return data frames. Operations include selecting columns, filtering rows, re-ordering rows, adding new columns, and summarizing data. Recall that a data frame is an R object for storing data as observations and variables.

A tibble (tabular data frame) is a type of data frame that make things easier when we use these functions. R is an old language. Some things that were useful 10 or 20 years ago get in the way now. 

To make a data frame a tibble use the `as_tibble()` function from the {tidyverse} set of packages. For example, `airquality` is an data frame object containing daily ozone and weather data. The function `class()` tells us that it is a data frame. After applying the function `as_tibble()` and assigning it to an object with the same name, the function `class()` tells us it is also now known as a tabled data frame.
```{r}
library(tidyverse)

class(airquality)
airquality <- as_tibble(airquality)
class(airquality)
```

Click on `airquality` in the environment. It is a data frame. Now let's see how the {dplyr} functions operate to wrangle the data frame `airquality`.

The function `select()` chooses variables by name. For example, choose the month, day, and temperature columns.
```{r}
select(airquality, Month, Day, Temp)
```

The first argument takes a data frame object (here `airquality`). So we can use the piping operator `%>%` to make the code easier to read. In this case the first argument is obtained from the name of the object in front of (before) the pipe. We read the pipe using the word _THEN_. 
```{r}
airquality %>%
  select(Month, Day, Temp)
```

The literal translations is "Take the `airquality` data frame then select the columns with names `Month`, `Day` and `Temp`.

Note here that the result is printed to the console but it is not assigned to an object.

If we want to assign the result to an object we need the assignment operator `<-`. To create a new data frame with only the temperature and ozone concentrations.
```{r}
df <- airquality %>%
        select(Temp, Ozone)
```

We include an assignment operator (`<-`) and an object name (here `df`). Nothing gets printed to the console but the object `df` shows up in our environment.

Note: The result is a data frame. The {tidyverse} syntax is to go from a data frame object to a data frame object.

The function `filter()` chooses observations based on specific values. Create a new data frame with only the observations where the temperature is at or above 80F.
```{r}
( df <- airquality %>%
          filter(Temp >= 80) )
```

The result is a data frame with the same 6 columns but now only 73 observations. Each of the observations has a temperature of at least 80F.

Note: Here I use a set of parentheses around the entire code chunk to assign and to print the result (or a summary of the result).

Create a new data frame keeping only observations (rows) where the temperature is at least 80F and the wind is less than 5 mph.
```{r}
( df <- airquality %>% 
  filter(Temp >= 80 & Wind < 5) )
```

The function `arrange()` orders the rows by values given in the column that is named.
```{r}
airquality %>%
  arrange(Solar.R)
```

Ordering is from the lowest value of radiation to the highest value. Here we see the first 10 rows. Note the rows are no longer chronological.

Repeat, but order by air temperature.
```{r}
airquality %>%
  arrange(Temp)
```

Importantly we can string the functions together. For example select the variables radiation, wind, and temperature then filter by temperatures above 90F and arrange by temperature.
```{r}
airquality %>%
  select(Solar.R, Wind, Temp) %>% 
  filter(Temp > 90) %>%  
  arrange(Temp)
```

The result is a data frame with three columns and 14 rows arranged by increasing temperatures above 90F. 

The `mutate()` function adds new columns to the data frame. For example, create a new column called `TempC` as the temperature in degrees Celsius. Also create a column called `WindMS` as the wind speed in meters per second.
```{r}
airquality %>%
  mutate(TempC = (Temp - 32) * 5/9,
         WindMS = Wind * .44704) 
```

The resulting data frame has 8 columns (two new ones) labeled `TempC` and `WindMS`.

On days when the temperature is below 60 F add a column giving the apparent temperature based on the cooling effect of the wind (wind chill) and then arrange from coldest to warmest apparent temperature.
```{r}
airquality %>%
  filter(Temp < 60) %>%
  mutate(TempAp = 35.74 + .6215 * Temp - 35.75 * Wind^.16 + .4275 * Temp * Wind^.16) %>%
  arrange(TempAp)
```

The `summarize()` function reduces (flattens) the data frame based on a function that computes a statistic. For example, to compute the average wind speed during July type
```{r}
airquality %>%
  filter(Month == 7) %>%
  summarize(Wavg = mean(Wind))

airquality %>%
  filter(Month == 6) %>%
  summarize(Tavg = mean(Temp))
```

We've seen functions that compute statistics including `sum()`, `sd()`, `min()`, `max()`, `var()`, `range()`, `median()`. Others include:

Summary function: Description
`n()`: Length of the column
`first()`: First value of the column
`last()`: Last value of the column
`n_distinct()`: Number of distinct values

Find the maximum and median wind speed and maximum ozone concentration values during the month of May. Also determine the number of observations during May.
```{r}
airquality %>%
  filter(Month == 5) %>%
  summarize(Wmax = max(Wind),
            Wmed = median(Wind),
            OzoneMax = max(Ozone),
            NumDays = n())
```

We get an `NA` for `OzoneMax` because there is at least one missing value. We fix this with the `na.rm = TRUE` argument in the function `max()`.
```{r}
airquality %>%
  filter(Month == 5) %>%
  summarize(Wmax = max(Wind),
            Wmed = median(Wind),
            OzoneMax = max(Ozone, na.rm = TRUE),
            NumDays = n())
```

If we want to summarize separately for each month we use the `group_by()` function. We split the data frame by some variable (e.g., `Month`), apply a function to the individual data frames, and then combine the output.

Find the highest ozone concentration by month. Include the number of observations (days) in the month.
```{r}
airquality %>%
  group_by(Month) %>%
  summarize(OzoneMax =  max(Ozone, na.rm = TRUE),
            NumDays = n())
```

Find the average ozone concentration when temperatures are above and below 70 F. Include the number of observations (days) in the two groups.
```{r}
airquality %>%
  group_by(Temp >= 70) %>%
  summarize(OzoneAvg =  mean(Ozone, na.rm = TRUE),
            NumDays = n())
```

On average ozone concentration is higher on warm days (Temp >= 70 F) days. Said another way; mean ozone concentration statistically depends on temperature.

The mean is a model for the data. The statistical dependency of the mean implies that a model for ozone concentration will likely be improved by including temperature as an explanatory variable.

In summary, the verbs are

Verb: Description
`select()`: selects columns; pick variables by their names
`filter()`: filters rows; pick observations by their values
`arrange()`: re-orders the rows
`mutate()`: creates new columns; create new variables with functions of existing variables
`summarize()`: summarizes values; collapse many values down to a single summary statistic
`group_by()`: allows operations to be grouped by variables

The six functions form the basis of a grammar for data. We can only alter a data frame by reordering the rows (`arrange()`), picking observations and variables of interest (`filter()` and `select()`), adding new variables that are functions of existing variables (`mutate()`), collapsing many values to a summary (`summarise()`), and conditioning on variables (`group_by()`).

The syntax of these functions all have the same three properties:

* The first argument is a data frame. The data frame is not named when using the `%>%` operator.
* The subsequent arguments describe what to do with the data frame. Columns in the data frame are named without using `$` or quotes.
* The result is a new data frame

The properties make it easy to chain together many simple lines of code to do complex data manipulations and summaries. Let's look at some examples from my research.

### US tornadoes

Import the data.
```{r}
Torn.df <- read_csv(file = "Tornadoes.csv")
Torn.df
```

The path length is in miles and the path width is in yards. We create new columns for length and width in metric units.

New columns are created with the `mutate()` function. Here we assign to the object `Torn.df` the original data frame but with three new columns. `Length` as the damage path length in meters and `Width` as the damage path width in meters.
```{r}
Torn.df <- Torn.df %>%
  mutate(Length = len * 1609.34,
         Width = wid * .9144) %>%
  glimpse()
```

The new data frame has the same columns as the original data frame but it now includes the columns `Length`, and `Width`.

The year is abbreviated and lower case and the EF damage rating is given by `mag`. Lets rename these columns.

To give a column a new name use the `rename()` function (new name = old name). For example to change the name of the column `yr` to `Year` and `mag` to `EF` type
```{r}
Torn.df <- Torn.df %>%
  rename(Year = yr,
         EF = mag) %>%
  glimpse()
```

The original names of `yr` and `mag` are replaced with `Year` and `EF`.

Next let's keep only columns of interest.

The `select()` function chooses specified columns by name to create a new data frame. Here we recycle the `Torn.df` name.
```{r}
Torn.df <- Torn.df %>%
  select(Year, 
         Month = mo, 
         ST = st, 
         EF, 
         date, 
         Length,
         Width, 
         Fatalities = fat,
         Injuries = inj)
glimpse(Torn.df)
```

Note that we also change the name of the column when we use the `=` sign. For example `Month = mo`. `mo` is the original name of the column but it gets changed to `Month`.  

We can select columns having common character string names. For example, we select columns containing only variables beginning with the letter `s` use the `starts_with()` function.
```{r}
Torn.df %>% 
  select(starts_with("s"))
```

Let's say we are interested in only the tornadoes that occurred during October of 1980.

The `filter()` function selects a subset of the rows of a data frame. The arguments are filtering (subsetting) expressions evaluated using column names of the data frame. For example, we can select all tornadoes recorded during October of 1980.
```{r}
Torn.df %>%
  filter(Month == 10, 
         Year == 1980)
```

Or lets create a new data frame containing only tornadoes originating in Wisconsin.
```{r}
TornWI.df <- Torn.df %>%
  filter(ST == "WI")
```

What tornado was the deadliest?

The function `arrange()` works like `filter()` except that instead of subsetting rows, it reorders them. It takes a data frame, and a set of column names (or more complicated expressions) to order by.

Here we use `desc()` together with `arrange()` to order a column by descending order of fatalities (variable name `Fatalities`).
```{r}
Torn.df %>%
  arrange(desc(Fatalities)) %>%
  glimpse()
```

The deadliest recorded tornado occurred in 2011, killing 158 people, with many of the deaths occurring in the city of Joplin, MO.

Again, note here the `glimpse()` function has no arguments. It inherits the _arranged_ data frame through the piping operator.

If we provide more than one column name, each additional column is used to break ties in the values of the preceding column.
```{r}
Torn.df %>%
  arrange(desc(Fatalities), desc(Injuries)) %>%
  glimpse()
```

Pull out a single variable with `pull()`

The function `pull()` pulls out a single variable from the data frame.
```{r}
Fatalities <- Torn.df %>%
  pull(Fatalities)
head(Fatalities)
```

The result is a vector. This is equivalent to `Fatalities <- Torn.df$fat`.

What is the median path length and path width?

The `summarize()` function collapses a data frame to a single row.
```{r}
Torn.df %>% 
  summarize(mL = median(Length),
            mW = median(Width))
```

The above functions are similar: The first argument is a data frame. This is implicit when using `%>%`. The subsequent arguments describe what to do with it, and you refer to columns in the data frame directly without using `$`. The result is a new data frame (except when using `pull()`).

Together these properties make it easy to chain together multiple simple steps to achieve a complex result. They functions provide the grammar for a data manipulation language. 

The remainder of the language comes from applying the five functions in various order and on various groups.

Grouped operations

The verb functions are powerful when we combine them with the idea of 'group by', repeating the operation individually on groups of observations within the data frame. 

We use the `group_by()` function to describe how to break a data frame down into groups of rows. We can then use the resulting object in the same functions as above; they'll automatically work 'by group' when the input is a grouped.

For example, what is the median path length and path width grouped by EF rating since 2007?

Here we filter the data frame for years starting with 2007 then group by EF rating before summarizing the path length and path width using the `median()` function.
```{r}
Torn.df %>%
  filter(Year >= 2007) %>%
  group_by(EF) %>%
  summarize(Count = n(),
            mL = median(Length),
            mW = median(Width))
```

The output is a table perhaps as part of our exploratory analysis.

We use `summarize()` with aggregate functions, which take a vector of values, and return a single number. Functions in the {base} package like `min()`, `max()`, `mean()`, `sum()`, `sd()`, `median()`, and `IQR()` can be used. The {dplyr} packages has others:

* `n()`: number of observations in the current group.
* `n_distinct()`: count the number of unique values.
* `first()`, `last()` and `nth()` - these work similarly to `x[1]`, `x[length(x)]`, and `x[n]` but give you more control of the result if the value isn't present.

For example, we use these to find the number of tornadoes by state and the number of months in which there was at least one tornado.
```{r}
Torn.df %>%
  group_by(ST) %>%
  summarize(months = n_distinct(Month),
            nT = n())
```

When we group by multiple variables, each summary peels off one level of the grouping. That makes it easy to progressively roll-up a dataset. As an example: how would we determine the number of tornadoes by day of year?

We first use the function `day()` from the {lubridate} package to extract the day of the month from a the column `date` (a vector of class `Date`) and add it to our data frame. We then use `group_by()` on the month and day. Finally we summarize by counting the number of cases.
```{r}
if(!require(lubridate)) install.packages(pkgs = "lubridate", repos = "http://cran.us.r-project.org")
library(lubridate)

Torn.df %>%
  mutate(Day = day(date)) %>%
  group_by(Month, Day) %>%
  summarize(nT = n())
```

The result is a data frame with the number of tornadoes by day of the year.

There are functions that combine some of the primitives. For example, we can use `tally()` instead of `summarize(nT = n())` or `count()` instead of both `group_by()` and `summarize()`.

For example, the following code does the same thing.
```{r}
Torn.df %>%
  mutate(Day = day(date)) %>%
  count(Month, Day)
```

What state had the most tornado fatalities?
```{r}
Torn.df %>%
  group_by(ST) %>%
  summarize(nF = sum(Fatalities)) %>%
  arrange(desc(nF))
```

### Florida precipitation

Suppose we are interested in whether it is getting wetter or drier in Florida during spring? One way to examine this question is to divide the years into two groups early and late and compute averages.

What is the average and variance of April rainfall since 1960?

Start by importing the data.
```{r}
FLp.df <- read_table(file = "http://myweb.fsu.edu/jelsner/temp/data/FLprecip.txt")
FLp.df
```

The first column are the years and the next 12 columns contain monthly averaged rainfall in inches.

Then select the values from the month of April (`Apr`) and year (`Year`), group by years > 1960, and finally, summarize the two groups of April rainfall with the mean and variance.
```{r}
FLp.df %>%
  select(Apr, Year) %>%
  group_by(Year > 1960) %>%
  summarize(Avg = mean(Apr),
            Var = var(Apr))
```

What month during 1965 was the wettest? How wet was it?

We use the `pivot_longer()` function from the {tidyverse} packages to turn the wide data frame into a long data frame. We want all the values but those in the first column (`Year`) to be in a single column (by default labeled `value`).
```{r}
FLp.df %>%
  pivot_longer(cols = -Year)
```

The result is a new data frame (not assigned an object name) with three columns. The first column labeled `Year` contains a list of years but year is repeated for each month. The second column labeled `name` contains the month abbreviations (which are the column names in the original wide data frame). The third column labeled `value` contains the corresponding monthly averaged rainfall.

Now we can filter on `Year` and summarize.
```{r}
FLp.df %>%
  pivot_longer(cols = -Year) %>%
  filter(Year == 1965) %>% 
  summarize(MostRain = max(value), 
            WhichMonth = which.max(value))
```

### Palmer penguins

As another example, consider the Palmer penguin data set from https://education.rstudio.com/blog/2020/07/palmerpenguins-cran/. 

The data set is located on the web and we import it as a data frame using the `read_csv()` function.
```{r}
loc <- "https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv"
penguins <- read_csv(file = loc)
penguins
```

The data are 344 individual penguins each described by species (Adelie, Chinstrap, Gentoo), where it was found (island name), length of bill (mm), depth of bill (mm), body mass (g), male or female, and year.

Each penguin belongs to one of three species. To see how many of the 344 penguins are in each species we use the `table()` function.
```{r}
table(penguins$species)
```

There are 152 Adelie, 68 Chinstrap, and 124 Gentoo penguins.

To create a data frame that only includes female penguins we type
```{r}
( df <- penguins %>% 
          filter(sex == "female") )
```
  
To create a data frame that only includes penguins that are not of species Adalie we type
```{r}
( df <- penguins %>% 
          filter(species != "Adelie") )
```

To create a data frame containing only penguins that weigh more than 6000 grams we type
```{r}
( df <- penguins %>% 
          filter(body_mass_g > 6000) )
```

To create a data frame with female penguins that have flippers longer than 220 mm we type
```{r}
( df <- penguins %>% 
          filter(flipper_length_mm > 220 & 
                 sex == "female") )
```

To create a data frame containing rows where the bill length value is NOT missing.
```{r}
( df <- penguins %>% 
          filter(!is.na(bill_length_mm)) )
```

Note that this filtering will keep rows with other column values missing values but there will be no penguins where the `bill_length` value is `NA`.

Finally, to compute the average bill length for each species.
```{r}
penguins %>%
  group_by(species) %>%
  summarize(AvgBL = mean(bill_length_mm, na.rm = TRUE))
```

### Summary

Manipulating data is part of the iterative cycle of data science, along with visualizing, and modeling.

The iterative cycle of data science:

1. Generate questions about our data.
2. Search for answers by manipulating, visualizing, and modeling the data.
3. Use what we learn to refine our questions and/or ask new ones.

We use questions as tools to guide our investigation. When we ask a question, the question focuses our attention on a specific part of our data set and helps us decide what to do.

For additional practice working with data using functions from the {tidyverse} set of packages.

* See http://r4ds.had.co.nz/index.html
* Cheat sheets http://rstudio.com/cheatsheets