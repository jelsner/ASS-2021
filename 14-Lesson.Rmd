---
title: "Lesson 14"
author: "James B. Elsner"
date: "February 24, 2021"
output:
  html_document: null
editor_options:
  chunk_output_type: console
---

**"We build our computer systems the way we build or cities; over time, without plan, on top of ruins."** – Ellen Ullman

## Fitting other spatial regression models

```{r}
library(sf)
if(!"columbus" %in% list.files()){
download.file("http://myweb.fsu.edu/jelsner/temp/data/columbus.zip",
              "columbus.zip")
unzip("columbus.zip")
}

CC.sf <- read_sf(dsn = "columbus", 
                 layer = "columbus")

f <- CRIME ~ INC + HOVAL
model.ols <- lm(formula = f, 
                data = CC.sf)
```

Tracts with higher income and housing values have lower crime rates. The marginal effect of income on crime holding housing values constant is -1.60 and the marginal effect of housing values holding income constant is -.27. The effects are statistically significant ($p$-values < .15).

We considered the spatial lag Y model and the spatial error model last time. Another option is to include spatially-lagged explanatory variables.
$$
y = X \beta + WX \theta + \varepsilon
$$

Now the weights matrix is post multiplied by the matrix of X variables. This is called the spatially lagged X model. Here $W$ is again the weights matrix and $\theta$ is a vector of coefficients for each lagged explanatory variable.

We fit the model using the `lmSLX()` function from the {spatialreg} package and save the model object as `model.slxm`.
```{r}
library(spatialreg)

nbs <- poly2nb(CC.sf)
wts <- nb2listw(nbs)

( model.slxm <- spatialreg::lmSLX(formula = f, 
                                  data = CC.sf, 
                                  listw = wts) )
```

Now, beside the direct marginal effects of income and housing value on crime, we also have the spatially lagged indirect effects.

The total effect of income on crime is the sum of the direct effect and indirect effect. And again, using the `impacts()` function we see this.
```{r}
spatialreg::impacts(model.slxm, listw = wts)
```

We get the impact measures and their standard errors, z-values and $p$-values with the `summary()` method applied to the output of the `impacts()` function.
```{r}
summary(spatialreg::impacts(model.slxm, listw = wts))
```

We see that income has a significant direct _and_ indirect effect on crime rates, but housing values only a significant direct effect.

Compare R squared values.
```{r}
summary(model.ols)$r.squared
summary(model.slxm)$r.squared
```

The spatially lagged model has an R squared value that is higher than the R squared value from the linear regression.

Updated thinking on how to proceed with finding the correct spatial model is to consider both the spatial Durbin error model (SDEM) and the spatial Durbin model (SDM). 

The SDEM is a SEM with a spatial lag X term added. To fit a SDEM we use the `errorsarlm()` function but include the argument `etype = "emixed"` to ensure that the spatially lagged X variables are added and the lagged intercept term is dropped when the weights style is row standardized (`"W"`).
```{r}
( model.sdem <- spatialreg::errorsarlm(formula = f, 
                                       data = CC.sf, 
                                       listw = wts,
                                       etype = "emixed") )
```

To SDM is a SLYM with a spatial lag X term added. To fit a SDM we use the `lagsarlm()` function but include the argument `type = "mixed"` to ensure that the spatially lagged X variables are added and the lagged intercept term is dropped when the weights style is row standardized (`"W"`).
```{r}
( model.sdm <- spatialreg::lagsarlm(formula = f, 
                                    data = CC.sf, 
                                    listw = wts,
                                    type = "mixed") )
```

How to do we choose between these two? Is the relationship between crime and income and housing values a global or local effect? Is there any reason to think that if something happens in one tract it will spillover across the entire city?  If crime happens in one tract does it influence crime across the entire city? If so, then it is a global relationship. Or should it be a more local effect? If there is more crime in one tract then maybe that influences crime in the neighboring tract but not tracts farther away. If so, then it is a local relationship.

We might think it is a more local relationship. So we start with the spatial Durbin error model and we look at the $p$-values on the direct and indirect effects.
```{r}
summary(impacts(model.sdem, listw = wts, R = 500), 
        zstats = TRUE)
```

We see that income has a statistically significant direct and indirect effect on crime. This means that tracts with higher income have lower crime and tracts whose _neighboring tracts_ have higher income also have lower crime. 

On the other hand, housing values have only a statistically significant direct effect on crime. Tracts with more expensive houses have lower crime but tracts whose neighboring tracts have more expensive houses do not imply lower crime. And the total effect of housing values on crime across the city is not significant. So if housing values go up in tracts citywide, there is no statistical evidence that crime will go down (or up).

Likelihood ratio tests. Null hypothesis is that we should restrict the model.
```{r}
LR.sarlm(model.sdem, 
         model.slxm)
```

The relatively small $p$-value suggests we should NOT restrict the spatial Durbin model to just the spatial lag X model.

See also: https://youtu.be/b3HtV2Mhmvk and https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2420725

## Fitting and interpreting geographic regressions

Another approach to modeling spatial data is to assume that the relationships between the response variable and the explanatory variables are modified by contextual factors that depend on location. We fit a separate regression model at each geographic location. This is similar to local measures of spatial autocorrelation where we estimate the statistic at each location.

This approach is useful for exploratory analysis (e.g., to show where the explanatory variables are most strongly related to the response variable) and is called geographically weighted regression (GWR) or geographic regression.

Since GWR fits a separate regression model to every spatial location in the dataset, it is not a single model but rather a procedure for fitting a set of models. All observations contribute to the fit but they are weighted inversely by their distance to the location. At short distances observations are given the largest weights based on a Gaussian function and a bandwidth. The bandwidth is specified or determined by cross-validation. 

GWR is used in epidemiology, particularly for research on infectious diseases and for evaluating health policies or health programs.

Linear regression is a model for the conditional mean. The mean of the response variable depends on the explanatory variable(s). Geographic regressions show how this dependency varies by location. It is an exploratory technique intended to indicate where local regression coefficients are different from the global values.

Continuing wit the Columbus crime data, we start by fitting a 'global' regression for the crime rates using income and housing values.
```{r}
f <- CRIME ~ INC + HOVAL
( model.lm <- lm(formula = f,
               data = CC.sf) )
```

We use functions from the {spgwr} package to fit geographic regressions.
```{r}
if(!require(spgwr)) install.packages(pkgs = "spgwr", repos = "http://cran.us.r-project.org")

library(spgwr)
```

The `sp` part of the package name indicates that the functions were developed to work with S4 spatial objects. We can use S3 simple features by specifying the locations as a matrix.
```{r}
Locations <- st_coordinates(st_centroid(CC.sf))

head(Locations)
```

We determine the optimal bandwidth for the Gaussian kernel (weighting function) using the `gwr.sel()` function. We need to specify the model formula, the data, and the coordinates.
```{r}
( bw <- gwr.sel(formula = f, 
               data = CC.sf,
               coords = Locations) )
```

Note: The argument `coords =` is the matrix of coordinates of points representing the spatial positions of the observations. It can be omitted if the data is an S4 spatial data frame from the {sp} package.

The procedure makes an initial guess at the optimal bandwidth distance and then fits local regression models at each location using weights that decay defined by the kernel and that bandwidth (distance).

We see that the first bandwidth was 2.22 distance units. The resulting prediction skill from fitting the regression models with that bandwidth is 7474 units. The resulting CV score is based on cross validation whereby skill is computed at each location when data from that location is not used to fit the regression models.

The procedure continues by increasing the bandwidth distance (to 3.59) and then computing a new CV score from refitting the regression models. Since the new CV score is higher (7480) than the initial CV score, the bandwidth is changed in the other direction (to 1.37) and the models again refit. With that bandwidth, the CV score is 7404, which is lower than the initial bandwidth so the bandwidth is shortened again. The procedure continues until no additional improvement in prediction skill occurs. 

This occurs at a bandwidth distance of .404 units, and this single value is assigned to the object we call `bw`.

After determining the optimal bandwidth distance we use the `gwr()` function to get the results from the regression using that bandwidth. The arguments are the same as with the `gwr.sel()` function but includes the `bandwith =` argument where we specify the object `bw`.
```{r}
model.gwr <- gwr(formula = f, 
                 data = CC.sf, 
                 coords = Locations,
                 bandwidth = bw)
```

The model and observed data are assigned to a list object with element names extracted using the `names()` function.
```{r}
names(model.gwr)
```

The first element is `SDF` containing the model output as a S4 spatial class data frame.
```{r}
class(model.gwr$SDF)
```

The structure of the S4 spatial class is obtained with the `str()` function and by setting the `max.level` argument to 2.
```{r}
str(model.gwr$SDF, max.level = 2)
```

Here we see there are 5 slots with the first slot being the attribute table labeled `@data`. The dimension of the attribute table is retrieved with the `dim()` function.
```{r}
dim(model.gwr$SDF)
```

There are 49 rows and 7 columns. Each row corresponds to a tract and information about the regression localized to the tract is given in the columns. The attribute names are extracted with the `names()` function.
```{r}
names(model.gwr$SDF)
```

They include the sum of the weights `sum.w` (the larger the sum the more often the tract is included in the local regressions--favoring smaller counties and ones farther from the borders of the spatial domain), the three regression coefficients one for each of the  explanatory variables (`INC` and `HOVAL`) and an intercept term, the residual (`gwr.e`), the predicted value (`pred`) and the local goodness-of-fit (`localR2`).

Importantly we can map where income has the most and least influence on crime.
```{r}
CC.sf$INCcoef <- model.gwr$SDF$INC

library(ggplot2)

ggplot(CC.sf) +
  geom_sf(aes(fill = INCcoef)) +
  scale_fill_viridis_c()
```

Most tracts have coefficients below zero, but areas in yellow indicate where income and crime values move in the same direction.

How about the coefficients on housing values?
```{r}
CC.sf$HOVALcoef <- model.gwr$SDF$HOVAL

ggplot(CC.sf) +
  geom_sf(aes(fill = HOVALcoef)) +
  scale_fill_viridis_c()
```

While the global coefficient is negative indicating crime rates tend to be lower in areas with higher housing values, the opposite is the case over much of city.

We put the vector of predictions into the `CC.sf` simple feature data frame giving it the column name `predGWR`.
```{r}
CC.sf$predGWR <- model.gwr$SDF$pred

tm_shape(CC.sf) +
  tm_fill("predGWR", title = "Predicted crimes\nper 1000") +
  tm_layout(legend.outside = TRUE)
```

The geographic regressions similarly capture the spatial pattern of homicides across the south. The spread of predicted values matches the observed spread better than the linear model. The pattern is also a smoother.

Where is the relationship the tightest?
```{r}
CC.sf$localR2 <- model.gwr$SDF$localR2

ggplot(CC.sf) +
  geom_sf(aes(fill = localR2)) +
  scale_fill_viridis_c()
```

Although crime rates are highest in the center of the city, the relationship between crime and income and housing values is largest across the eastern part of the city.

When we use a regression model to fit data that vary spatially we are assuming an underlying stationary process. This means we believe the explanatory variables 'provoke' the same statistical response across the entire domain. If this is not the case then it shows up in a map of correlated residuals. One approach to investigate things further is to use geographic regression.

## Disease mapping

Spatial regression models are often used to map the spread of diseases. It is typical to use a standardized incidence ratio (SIR) defined as the ratio of the observed to the _expected_ number of disease cases. Small areas can give extreme SIRs due to low population sizes or small samples. Extreme values of SIRs may be misleading and unreliable for reporting.

In these cases it is better to estimate disease risk using a spatial regression model. Models can incorporate information from neighboring areas and covariate information resulting in smoothing (shrinking) of extreme values.

Consider data of lung cancer cases in Pennsylvania counties from the {SpatialEpi} package. The county boundaries for the state are in the list object `pennLC` with element name `spatial.polygon`. We change the native spatial polygons S4 object to an S3 simple feature data frame using the `st_as_sf()` function from the {sf} package and display a map of the counties.
```{r}
if(!require(SpatialEpi)) install.packages("SpatialEpi", repos = "http://cran.us.r-project.org")
library(SpatialEpi)

LC.sp <- pennLC$spatial.polygon
LC.sf <- st_as_sf(LC.sp)

ggplot(LC.sf) +
  geom_sf()
```

For each region $i$, $i = 1, \ldots, n$ the SIR is defined as the ratio of observed counts to the expected counts
$$
\hbox{SIR}_i = Y_i/E_i.
$$

The expected count $E_i$ is the total number of cases that one would expect if the population of area $i$ behaves the way the standard population behaves. If we ignore differences in rates for different stratum (e.g., age groups) then we compute the expected counts as
$$
E_i = r^{(s)} n^{(i)},
$$
where $r^{(s)}$ is the rate in the standard population (total number of cases divided by the total population across all regions), amd $n^{(i)}$ is the population of region $i$.

Then $\hbox{SIR}_i$ indicates whether region $i$ has higher ($\hbox{SIR}_i > 1$), equal ($\hbox{SIR}_i = 1$) or lower ($\hbox{SIR}_i < 1$) risk than expected relative to the standard population.

When applied to mortality data, the ratio is known as the standardized mortality ratio (SMR).

The data frame `pennLC$data` from the {SpatialEpi} package contains the number of lung cancer cases and the population of Pennsylvania at county level, stratified on race (white and non-white), gender (female and male) and age (under 40, 40-59, 60-69 and 70+). 

We obtain the number of cases for all the strata together in each county by aggregating the rows of `pennLC$data` by county and adding up the number of cases.
```{r}
County.df <- pennLC$data %>%
  group_by(county) %>%
  summarize(Y = sum(cases))
head(County.df)
```

We calculate the expected number of cases in each county using indirect standardization. The expected counts in each county represent the total number of disease cases one would expect if the population in the county behaved the way the population of Pennsylvania behaves. We can do this by using the `expected()` function from the {SpatialEpi} package. This function has three arguments, namely,

* `population`: vector of population counts for each strata in each area,
* `cases`: vector with the number of cases for each strata in each area,
* `n.strata`: number of strata.

The vectors `population` and `cases` need to be sorted by area first and then, within each area, the counts for all strata need to be listed in the same order. All strata need to be included in the vectors, including strata with 0 cases. Here we use the `arrange()` function from the {dplyr} package.
```{r}
Strata.df <- pennLC$data %>%
  arrange(county, race, gender, age)
head(Strata.df)
```

Then, we obtain the expected counts E in each county by calling the `expected()` function from the {SpatialEpi} package where we set population equal to `Strata.df$population` and cases equal to `Strata.df$cases`. There are 2 races, 2 genders and 4 age groups for each county, so number of strata is set to 2 x 2 x 4 = 16.
```{r}
( E <- expected(
  population = Strata.df$population,
  cases = Strata.df$cases, 
  n.strata = 16
) )
```

Now we add the observed count `Y`, the expected count `E` the computed SIR to `sfdf` and make a map of SIR.
```{r}
LC.sf <- LC.sf %>%
  mutate(Y = County.df$Y,
         E = E,
         SIR = Y/E)

ggplot(LC.sf) + 
  geom_sf(aes(fill = SIR)) +
  scale_fill_gradient2(midpoint = 1, 
                       low = "blue", 
                       mid = "white", 
                       high = "red") +
  theme_minimal()
```

Counties with SIR = 1 (color white) the number of lung cancer cases observed is the same as the number of expected cases. In counties where SIR > 1 (color red), the number of lung cancer cases observed is higher than the expected cases. Counties where SIR < 1 (color blue) have fewer lung cancer cases observed than expected.

With rare diseases in regions with few people, the expected counts may be very low and SIRs may be misleading. Therefore, it is preferred to estimate disease risk by using models that borrow information from neighboring areas, and incorporate covariate information. This results in smoothing (shrinkage) of extreme values.

Let the observed counts $Y$ be modeled with a Poisson distribution having a mean $E\theta$, where $E$ are the expected counts and $\theta$ are the relative risks. The logarithm of the relative risk is expressed as the sum of an intercept that models the overall disease risk level, and random effects to account for local variability.

The relative risk quantifies whether an area has a higher ($\theta > 1$) or lower ($\theta < 1$) risk than the average risk in the population. For example if $\theta_i = 2$, then the risk in area $i$ is twice the average risk in the population.

The model is expressed as
$$
Y \sim \hbox{Poisson}(E\theta) \\
\log(\theta) = \alpha + u + v
$$

The parameter $\alpha$ represents the overall risk in the region of study, $u$ is the spatially structured random effect representing the dependency in risk across neighboring areas (spatial autocorrelation), and $v$ is the uncorrelated random noise modeled as $v \sim N(0, \sigma_v^2)$.

It is common to include explanatory variables to quantify risk factors (e.g., distance to nearest coal plant). Thus the log($\theta$) is expressed as
$$
\log(\theta) = \alpha + X\beta + u + v
$$
where $X$ are the explanatory variables and $\beta$ are the associated coefficients. A coefficient is interpreted such that a one-unit increase in the explanatory variable value changes the relative risk by a factor $\exp(\beta)$, holding the other variables constant.

A popular form for the combined spatially structured random effect and the uncorrelated random effect is the Besag-York-Mollié (BYM) model which assigns a conditional autoregressive distribution to $u$ as
$$
u | u_{j \ne i} \sim N(\bar u_{\delta}, \frac{\sigma_u^2}{n_{\delta}})
$$
where $\bar  u_{\delta_i} = \Sigma_{j \in \delta_i} u_j/n_{\delta_i}$ and where $\delta_i$ is the set of neighbors of area $i$ and $n_{\delta_i}$ is the number of neighbors of area $i$.

In words, the logarithm of the disease incidence rate in area $i$ conditional on the incidence rates in the neighborhood of $i$ is modeled with a normal distribution centered on the neighborhood average ($\bar  u_{\delta_i}$) with a variance scaled by the number of neighbors. This is called the conditional autoregressive (CAR) distribution.

More info: https://www.paulamoraga.com/book-geospatial/sec-geostatisticaldataexamplespatial.html

The syntax for the BYM model in INLA is given as
```{r eval=FALSE}
formula <- Y ~
  f(ID_u, model = "besag", graph = g, scale.model = TRUE) +
  f(ID_v, model = "iid")
```

The formula includes the response in the left-hand side, and the fixed and random effects on the right-hand side. By default, the formula includes an intercept. 

The random effects are set using `f()` with parameters equal to the name of the index variable, the model, and other options. The BYM formula includes a spatially structured random effect with index variable with name `ID_u` and equal to c(1, 2, ..., I), and model `"besag"` with a CAR distribution and with neighborhood structure given by the graph `g`. The option `scale.model = TRUE` is used to make the precision parameter of models with different CAR priors comparable. 
The formula also includes an uncorrelated random effect with index variable with name `ID_v` again equal to c(1, 2, ..., I), and model "iid". This is an independent and identically distributed zero-mean normally distributed random effect. Note that both the `ID` variables are identical but need to be specified as two different objects since R-INLA does not allow to include two effects with `f()` that use the same index variable. 

The BYM model can also be specified with the model "bym" which defines both the spatially structured random effect and the uncorrelated random effect ($u$ and $v$).