---
title: "Lesson 10"
author: "James B. Elsner"
date: "February 10, 2021"
output:
  html_document: null
editor_options:
  chunk_output_type: console
---

**""You haven't mastered a tool until you understand when it should not be used."** â€“ Kelsey Hightower

Today: Mapping examples using the tornado data. 

## Example: Tornado locations by month in the continental U.S.

Import the tornado data. Remove Alaska, Hawaii, and Puerto Rico tornadoes. The native CRS is latitude/longitude so we transform it to a Web Mercator (EPSG 3857) used by Google Maps, OpenStreetMap, Bing, ArcGIS, ESRI.
```{r}
Torn.sf <- read_sf(dsn = "1950-2018-torn-initpoint",
                   layer = "1950-2018-torn-initpoint") %>%
      filter(!st %in% c("HI", "AK", "PR")) %>%
      filter(yr >= 1994) %>%
      st_transform(crs = 3857)
```


Suppose we want a map showing the location of tornadoes in the continental U.S. by month. First add the world map with countries as a polygon layer (fill is gray by default). Then overlay the U.S. country polygons and color them white. Then add the tornado genesis locations as dots faceted by month. Then add the state polygons as borders. Use a North American Lambert Azimuthal Equal Area Projection and make this the master layer. Finally add cartographic elements.
```{r, eval=FALSE}
tm_shape(world) +
  tm_polygons() +
tm_shape(world[world$name_long == "United States", ]) +
  tm_polygons(col = "white") +
tm_shape(Torn.sf) +
  tm_dots() + 
  tm_facets(by = "mo", as.layers = TRUE) +
tm_shape(States, is.master = TRUE) + 
  tm_borders() +
  tm_compass(type = "arrow", position = c("left", "bottom")) +
  tm_scale_bar(position = c("left", "bottom"), text.size = .75) +
  tm_style("natural") +
  tm_layout(main.title = "Contiguous U.S. Tornadoes [1950-2018]",
            main.title.position = "center", main.title.size = .85,
            panel.labels = month.name) +
  tm_credits(c(rep("", 11), "Data Source: U.S. SPC"), 
             position = c("right", "bottom"))
```

We can clearly see the spread of tornado activity from the southeast in January to the central Plains in May to the northern Plains during July and August and then back to the southeast in December.

## An inset map (extra)

An inset map contextualizes the geographic study area. Here we create a map of the central part of New Zealand's Southern Alps. The inset map shows where the main map is in relation to all of New Zealand. 

The first step is to define the area of interest. Here it is done here by creating a new spatial object `nz_region` using the `st_bbox()` function and the `st_as_sfc()` to make it a simple feature column.
```{r}
nz_region <- st_bbox(c(xmin = 1340000, xmax = 1450000,
                       ymin = 5130000, ymax = 5210000),
                     crs = st_crs(nz_height)) %>% 
  st_as_sfc()
```

The second step is to create a base map showing New Zealand's Southern Alps area. This is the closeup view of where the most important message is stated. The region is clipped to the simple feature column `nz_region` created above. The layers include a raster of elevations and locations of high points. A scale bar is included.
```{r}
nz_height_map <- tm_shape(nz_elev, 
                          bbox = nz_region) +
  tm_raster(style = "cont", 
            palette = "YlGn", 
            legend.show = TRUE) +
  tm_shape(nz_height) + 
  tm_symbols(shape = 2, 
             col = "red", 
             size = 1) +
  tm_scale_bar(position = c("left", "bottom"))

nz_height_map
```

The third step is to create the inset map. It gives a context and helps to locate the area of interest. This map clearly indicates the location of the main map.
```{r}
nz_map <- tm_shape(nz) + 
  tm_polygons() +
  tm_shape(nz_height) + 
  tm_symbols(shape = 2, 
             col = "red", 
             size = .1) + 
  tm_shape(nz_region) + 
  tm_borders(lwd = 3)

nz_map
```

The final step is to combine the two maps. The `viewport()` function from the {grid} package is used to give a center location (x and y) and the size (width and height) of the inset map.
```{r}
library(grid)

nz_height_map
print(nz_map, 
      vp = viewport(.8, .27, width = .5, height = .5))
```

Additional details are available here: https://geocompr.robinlovelace.net/adv-map.html

## Interactive maps

Leaflet is a popular open-source platform (javascript) for making/serving interactive maps. The {leaflet} package provides access to the platform.

As an example, here we create a world map by using the default mapping arguments in `leaflet()` and zoomable tiles with the `addTiles()` layer. The piping operator (`%>%`) is used to 'add' layers. 
```{r}
if(!require(leaflet)) install.packages(pkgs = "leaflet", repos = "http://cran.us.r-project.org")
library(leaflet)

m <- leaflet() %>% 
  addTiles()
m
```

Note: if the map doesn't render in your Viewer tab, then click the `Viewer` tab and select "Show in new window".

Here we use `setView()` with longitude and latitude arguments in decimal degrees to center the map on FSU and use a zoom of 17.
```{r}
m <- m %>%
  setView(lng = -84.29849, 
          lat = 30.44188, 
          zoom = 17)
m
```

A nice feature of {tmap} is that we can create an interactive map using the same code as we used to create a static map. 

For example our static map of New Zealand (`map_nz`) is viewed interactively by switching to view mode.
```{r}
tmap_mode("view")
map_nz
```

With the interactive mode turned on, all maps produced with {tmap} will launch as zoomable HTML. This feature includes the ability to specify the basemap with `tm_basemap()` (or `tmap_options()`) as demonstrated here.
```{r}
map_nz + 
  tm_basemap(server = "OpenTopoMap")
```

Q: Why is there no topography for New Zealand?

We can also create interactive maps with the `tmap_leaflet()` function.

The view mode in {tmap} works with faceted plots. The argument sync in `tm_facets()` is used to produce multiple maps with synchronized zoom and pan settings.
```{r}
world_coffee <- left_join(world, 
                          coffee_data, 
                          by = "name_long")
tm_shape(world_coffee) + 
  tm_polygons(c("coffee_production_2016", 
                "coffee_production_2017")) + 
  tm_facets(nrow = 1, sync = TRUE)
```

Change the view mode back to plot.
```{r}
tmap_mode("plot")
```

## Example: Tornado occurrences on a grid

Convert the tornado simple feature data frame to geographic coordinates.
```{r}
Torn.sf <- Torn.sf %>%
  st_transform(crs = 4326)
```

Create the leaflet map with a view set on campus. First use the `addTiles()` function and then the `addPolylines()` function with the argument `data = Alltors2.sfdf`. The piping operator is used to add layers.
```{r}
m <- leaflet() %>% 
  setView(-84.29849, 30.44188, zoom = 17) %>%
  addTiles() %>%
  addPolylines(data = Alltors2.sfdf)
m
```
  
We can also use the `mapView()` function from the {mapview} package. It also provides interactivity for easy and quick visualization during spatial data analysis. But it is not intended for fine-tuned presentation quality map production.
```{r}
if(!require(mapview)) install.packages(pkgs = "mapview", repos = "http://cran.us.r-project.org")
library(mapview)

mapView(Alltors2.sfdf, 
        zcol = "mag")
```

Use `mapView()` to create an interative map of tornado counts on a raster. First create a raster of grid cells at a resolution of a quarter of a degree latitude and longitude. Use the `rasterize()` function from the {raster} package to count the number of tornado occurrences in each cell. 

We first create the raster with a cell resolution of 1/4 degree. We specify `field = "om"` so the result is a raster layer rather than a raster brick (all variables in `Alltors2.sfdf`).
```{r}
library(raster)

r <- raster(xmn = -125, xmx = -67, 
            ymn = 24, ymx = 50)
res(r) <- .25
Tor_r <- rasterize(x = Alltors2.sfdf, 
                   y = r, 
                   field = "om",
                   fun = "count")
```

Finally use the `mapView()` function to create the interactive map.
```{r}
mapView(Tor_r,
        alpha.regions = .35)
```

I encourage to take a look at the functions in the {cartography} package for making maps. https://www.rdocumentation.org/packages/cartography/versions/2.4.2

## Spatial neighborhoods and weights

The concept of autocorrelation plays a central role in spatial statistics. How it gets estimated and exploited depends on the spatial geometry of the data. In the case where data are aggregated to polygons (or raster cells) spatial autocorrelation measures the degree to which attribute values tend to cluster. Keep in mind that attributes are variables in a spatial data frame (either as a column in a simple feature object or as a layer in a raster object). 

Clustering arises from:

* Association: whatever is causing an attribute to have a certain value in one area causes the attribute to have a similar value in areas nearby. Crime rates in nearby neighborhoods might tend to cluster due to similar factors such as economic status and the amount of policing. Non-infectious diseases (e.g., lung cancer) might have similar rates in neighborhoods close to an oil refinery.

* Causality: something within a given area directly influences outcomes within nearby areas. The broken window theory of crime suggests that poverty, lack of maintenance, and petty crime tends to breed more crime due to a perceived breakdown in civil order.

* Interaction: the movement of people, goods or information creates relationships between areas. Infectious diseases might spread from a source region thus increasing the disease rates in surrounding areas as the direct result of contact or movement of people between regions.

Spatial statistics quantify, and condition on, autocorrelation but they are silent about physical causes. Understanding the reason for autocorrelation is important for causal inference because the causal mechanism might be confounded by it. Divorce rates are high in states in the South, but so is the number of Waffle Houses. Understanding causation requires domain specific knowledge.

When variables are spatially aggregated to regions, autocorrelation is quantified by calculating how similar a value in region $i$ is to the value in region $j$ and weighting this similarity by how 'close' region $i$ is to region $j$. Closer regions have greater weight.

High similarities with high weight (similar values close together) yield high values of spatial autocorrelation. Low similarities with high weight (dissimilar values close together) yield low values of spatial autocorrelation. 

Let $\hbox{sim}_{ij}$ denote the similarity between values $Y_i$ and $Y_j$, and let $w_{ij}$ denote a weight describing the 'distance' between regions $i$ and $j$, for $i$, $j$ = 1, ..., $N$. 

Then a spatial autocorrelation index (SAI) is given by
$$
\hbox{SAI} = \frac{\sum_{i,j=1}^N w_{ij}\hbox{sim}_{ij}}{\sum_{i,j=1}^N w_{ij}}
$$
which represents the weighted similarity between regions. The collection of weights is called a spatial weights matrix. The spatial weights matrix defines the neighbors for each region and their strength of association.

For cells in a raster under the rook-contiguity criterion, $w_{ij}$ = 1 if cell $i$ and $j$ share a boundary, and 0 otherwise. In this case $w_{ij}$ = $w_{ji}$. Also a cell is not a neighbor to itself so $w_{ii}$ = 0.

As an alternative we can define center locations from a set of polygon regions and let $w_{ij}$ = 1 if the center of region $i$ is near the center of region $j$ and 0 otherwise. In this case we need to decide on the number of nearest neighbors.

We can also define neighbors by distance. For example, if $d_{ij}$ is the distance between centers $i$ and $j$, we can let $w_{ij}$ = 1 if $d_{ij}$ < $\delta$ and 0 otherwise.

### Example: Crime in Columbus, Ohio

Consider crime data at the tract level in the city of Columbus, Ohio (Anselin, 1988: Spatial Econometrics. Boston, Kluwer Academic). The tract polygons are projected with arbitrary spatial coordinates.
```{r}
library(sf)

download.file("http://myweb.fsu.edu/jelsner/temp/data/columbus.zip",
              destfile = "data/columbus.zip")
unzip("data/columbus.zip", exdir = "data")

CC.sf <- read_sf(dsn = "data/columbus")
```

The simple feature data frame contains the following names and geometry.
```{r}
names(CC.sf)
st_geometry(CC.sf)
```

Create a choropleth map of the crime rates (`"CRIME"`). Residential burglaries and vehicle thefts per 1000 households.
```{r}
library(tmap)

tm_shape(CC.sf) +
  tm_fill("CRIME",
          title = "") +
  tm_borders(col = "gray70") +
  tm_layout(title = "Burglary & Vehicle Thefts\n/1000 Households",
            legend.outside = TRUE)
```

Alternatively
```{r, eval=FALSE}
library(ggplot2)

ggplot(data = CC.sf) + 
  geom_sf(aes(fill = CRIME), col = "gray70") +
  ggtitle("Burglary & Vehicle Thefts/1000 Households")
```

High crime areas tend to cluster. Spatial autocorrelation quantifies this clustering. To quantify we first need to define a list of neighbors for each polygon. 

List of neighbors

We create a list of neighbors using the `poly2nb()` function from the {spdep} package. The function now works on S4 spatial classes and simple features.
```{r}
library(spdep)

( nbs <- poly2nb(CC.sf) )
```

The `nb` in the `poly2nb()` function names stands for neighbor list object. The function builds the list from regions based on contiguity. Neighbors must share one or more geometry points. By default the contiguity is defined as having at least one point in common. This is changed by using the argument `queen = FALSE`.

There are 49 tracts (polygons). Each tract is bordered by at least one other tract (each tract is bordered by at least one tract). The average number of neighbors is 4.8. The total number of neighbors over all tracts is 236. This represents 9.8% of all possible connections (if every tract is a neighbor of itself and every other tract 49 * 49).

A graph of the neighbor links is obtained with the `plot()` method. The arguments include the neighbor list object (`nbs`) and the location of the polygon centers, which are extracted from the simple feature data frame using the `st_centroid()`.
```{r}
plot(nbs, 
     st_centroid(CC.sf$geometry))
```

The graph is a network showing the contiguity pattern (topology). Tracts close to the center of the city have more neighbors than those on the outskirts.

The number of links per node (tract)--link distribution--is obtained with the `summary()` method.
```{r}
summary(nbs)
``` 

The list of neighboring tracts for the first two tracts.
```{r}
nbs[[1]]
nbs[[2]]
```

The first tract has two neighbors that include tracts 2 and 3. The neighbor numbers are stored as an integer vector. Tract 2 has three neighbors that include tracts 1, 3, and 4. Tract 5 has 8 neighbors and so on. The function `card()` tallies the number of neighbors by tract.
```{r}
card(nbs)
```

Tract 5 has 8 neighbors.

Weights matrix

Next weights are added to the neighbor list object to create a weights matrix. The weights specifying how 'close' each neighbor is. This is done with the `nb2listw()` function. The function turns the neighbor list object into a spatial weights object. By default the weighting scheme gives each link the same weight equal to the multiplicative inverse of the number of neighbors.
```{r}
wts <- nb2listw(nbs)

class(wts)
```

This new `wts` object is a list with two elements. The first element (`listw`) is the weights matrix and the second element (`nb`) is the neighbor list object.
```{r}
summary(wts)
```

The network statistics are given along with information about the weights. By default all neighboring tracts are assigned a weight equal to the inverse of the number of neighbors  (`style = "W"`). For a tract with 5 neighbors each neighbor gets a weight of 1/5. The sum over all weights (`S0`) is the number of tracts.

To see the weights for the first two tracts type
```{r}
wts$weights[1:2]
```

The `$weights` list a sparse representation of the spatial weights matrix. The full matrix has dimensions 49 x 49.

To see the neighbors of the first two tracts type
```{r}
wts$neighbours[1:2]
```

Tract 1 has two neighbors (tract 2 & 3) so each are given a weight of 1/2. Tract 2 has three neighbors (tract 1, 3, & 4) so each are given a weight of 1/3.

With the weights matrix specified and saved as an object we are ready to compute a metric of spatial autocorrelation.

Caution: Contiguity can result in areas having no neighbors; islands for example. By default the `nb2listw()` function assumes each area has at least one neighbor. If this is not the case we need to specify how areas without neighbors are handled using the argument `zero.policy = TRUE`. This permits the weights list to be formed with zero-length weights vectors.

For example, consider the districts in Scotland.
```{r}
download.file("http://myweb.fsu.edu/jelsner/temp/data/scotlip.zip",
              "scotlip.zip")
unzip("scotlip.zip")

SL.sf <- read_sf(dsn = "scotlip", 
                 layer = "scotlip")
plot(SL.sf$geometry)
```

Here there are three island districts.

Create a list of neighbors.
```{r}
( nbs2 <- poly2nb(SL.sf) )
```

Three regions with no links.

Use the `nb2listw()` function with the argument `zero.policy = TRUE`. Otherwise we get an error saying the empty neighbor sets are found.
```{r}
wts2 <- nb2listw(nbs2,
                 zero.policy = TRUE)
head(wts2$weights)
```

Moran I

A commonly used autocorrelation statistic is Moran I. Moran I follows the basic form of spatial autocorrelation indexes where the similarity between regions $i$ and $j$ is proportional to the product of the deviations from the mean such that
$$
\hbox{sim}_{ij} \propto (Y_i - \bar Y) (Y_j - \bar Y)
$$

where $i$ indexes the region and $j$ indexes the neighbors of $i$. The value of $\hbox{sim}_{ij}$ is large when the $Y$ values in the product are on the same side of their respective means and small when they are on opposite sides of their respective means.

The formula for I is
$$
\hbox{I} = \frac{N} {W} \frac {\sum_{i,j} w_{ij}(Y_i-\bar Y) (Y_j-\bar Y)} {\sum_{i} (Y_i-\bar Y)^2}
$$
where $N$ is the number regions, $w_{ij}$ is the matrix of spatial weights, and $W$ is the sum over all weights.

Consider the following spatial grid of cells containing random attribute values.
```{r}
if(!require(spatstat)) install.packages(pkgs = "spatstat", repos = "http://cran.us.r-project.org")
library(spatstat)

set.seed(6750)
Y <- ppp(runif(200, 0, 1), 
         runif(200, 0, 1))
plot(quadratcount(Y), main = "")
```

The formula for I results in one value for the entire grid. 

Let's first consider a single cell on the grid ($N$ = 1). Here the middle cell (row 3, column 3). Let $i$ = 3 in the above formula and let $j$ index the cells touching the center cell in reading order starting with cell (2, 2), then cell (2, 3), etc.

Assume each neighbor is given a weight of 1/8 so $W$ = 1. Then the value of I for the single center cell is 
I_{3, 3} = (6 - mean(y)) * 
                     ((8 - mean(y)) + 
                     (3 - mean(y)) +
                     (9 - mean(y)) +
                     (12 - mean(y)) +
                     (10 - mean(y)) +
                     (10 - mean(y)) +
                     (9 - mean(y))) / 
            (6 - mean(y))^2)

```{r}
y <- c(3, 10, 7, 12, 5, 11, 8, 3, 9, 12, 
      6, 12, 6, 10, 3, 8, 10, 10, 9, 7, 
      5, 10, 8, 5, 11)
( yb <- mean(y) )
```

```{r}
Inum_i <- (6 - yb) * 
                 ((8 - yb) + (3 - yb) + (9 - yb) + 
                  (12 - yb) + (10 - yb) + (10 - yb) + 
                  (10 - yb) + (9 - yb))
Iden_i <- (6 - yb)^2
Inum_i/Iden_i
```

The I value of -3.5 indicates that the center cell which has a value below the average over all 25 cells is mostly surrounded by cells having values above the average.

Repeat this calculation for every cell and then take the sum.

This is what the function `moran()` from the {spdep} package does. The first argument is the vector containing the values for which we are interested in determining the magnitude of the spatial autocorrelation and the second argument is the `listw` object. 

Further, we need to specify the number of regions and the sum of the weights `S0`. The latter is obtained from the `Szero()` function applied to the `listw` object.

Returning to the Columbus crime data here we let `m` be the number of census tracts and `s` be the sum of the weights. We then apply the `moran()` function on the variable `CRIME` in
```{r}
m <- length(CC.sf$CRIME)
s <- Szero(wts)

moran(CC.sf$CRIME, 
      listw = wts, 
      n = m, 
      S0 = s)
```

The function returns the Moran I statistic and the kurtosis (K) of the distribution of crime values. Moran I ranges from -1 to +1. The value of .5 for the crime rates indicates fairly high spatial autocorrelation. This is expected based on the clustering of crime in the central city. Positive values of Moran I indicate clustering and negative values indicate inhibition.

Kurtosis is a statistic measuring the peakedness of the distribution of the attribute values. A normal distribution has a kurtosis of 3. If the kurtosis is too large (or small) relative to a normal distribution then the inferences we make with Moran I are suspect.

Another index of spatial autocorrelation is the Geary C statistic. The equation is 
$$
\hbox{C} = \frac{(N-1) \sum_{i,j} w_{ij} (Y_i-Y_j)^2}{2 W \sum_{i}(Y_i-\bar Y)^2} 
$$
where again $W$ is the sum over all weights ($w_{ij}$) and $N$ is the number of areas.

The syntax of the `geary()` function is similar to the syntax of the `moran()` function except we also specify `n1` to be one minus the number of polygons.
```{r}
geary(CC.sf$CRIME, 
      listw = wts,
      n = m, 
      S0 = s, 
      n1 = m - 1)
```

Values for Geary C range from 0 to 2 with 1 indicating no spatial autocorrelation. Values less than 1 indicate positive autocorrelation. Both I and C are global measures of autocorrelation, but C is more sensitive to local variations in autocorrelation.

Rule of thumb: If the interpretation of Geary C is much different than the interpretation of Moran I then consider computing local measures of spatial autocorrelation.
