---
title: "Lesson 26"
author: "James B. Elsner"
date: "April 12, 2021"
output:
  pdf_document: default
  html_document: null
editor_options:
  chunk_output_type: console
---

**"When debugging, novices insert corrective code; experts remove defective code."** â€“ Richard Pattis

## Creating a spatial interpolation using more than one variable (cokriging)

Statistical interpolation can be extended to obtain surfaces of multiple field variables. The idea is that if two field variables are correlated then information about the spatial correlation in one field variable can help provide information about values in the other field variable. The spatial variability of one variable is correlated with the spatial variability of the other variable. And this idea is not limited to only two variables. 

Here we consider data measuring concentrations of heavy metals in the flood plain of the Meuse River in Holland. The data are available in the {sp} package.
```{r}
library(gstat)
library(sf)
library(sp)

data(meuse)
names(meuse)

meuse.sf <- st_as_sf(x = meuse,
                    coords = c("x", "y"),
                    crs = 28992)
```

Suppose we are interested in the spatial distribution of all the heavy metals in the soils along the river.

First we need to organize the data as a `gstat` object. This is done with the `gstat()` function which orders (and copies) the field variables into a single object. It is done successively with the `gstat()` function.

Here we specify the trend using the square root of the distance to river as we did previously.
```{r}
g <- gstat(NULL, "logCd", log(cadmium) ~ sqrt(dist), meuse.sf)
g <- gstat(g, "logCu", log(copper) ~ sqrt(dist), meuse.sf)
g <- gstat(g, "logPb", log(lead) ~ sqrt(dist), meuse.sf)
g <- gstat(g, "logZn", log(zinc) ~ sqrt(dist), meuse.sf)
g
```

Next we use the `variogram()` function to compute empirical variograms. The function, when operating on a `gstat` object, computes all direct and cross variograms.
```{r}
v <- variogram(g)
plot(v)
```

The plot method displays the set of direct and cross variograms. The direct variograms are shown in the four panels along the diagonal of the triangle of plots.

The cross variograms are shown in the six panels below the diagonal. For example, the cross variogram between the values of cadmium and copper is given in the second row of the first column. 

Note: The cross variogram is analogous to the `Kcross()` function from the {spatstat} package.

Next we use `fit.lmc()` to fit separate models to each of the empirical variograms. We use an initial partial sill and nugget equal to one and a range of 800.
```{r}
vm <- fit.lmc(v, g, 
              vgm(psill = 1, model = "Sph", 
              range = 800, nugget = 1))
plot(v, vm)
```

As the variograms indicate, the variables have a strong cross correlations. Because these variables are co-located, we can also compute direct correlations.
```{r}
cor(meuse[c("cadmium", "copper", "lead", "zinc")])
```

The correlation matrix confirms strong cross correlation among the four variables at zero lag. The cross variogram generalizes these correlations across lag distance.

Given the variogram models, cokriged maps are produced using the `predict()` method after setting the grid locations for interpolation. The CRS for the grid locations matches the CRS of the data.
```{r}
data(meuse.grid)

grid.sf <- st_as_sf(x = meuse.grid,
                    coords = c("x", "y"),
                    crs = 28992)

cok <- predict(vm, grid.sf)
names(cok)
```

The predictions for logarithm of zinc concentration are plotted.
```{r}
library(tmap)

tm_shape(cok) +
  tm_dots(col = "logZn.pred", size = .2)
```

Compare with predictions using only zinc.
```{r}
v2 <- variogram(log(zinc) ~ sqrt(dist), 
                data = meuse.sf)
vm2 <- fit.variogram(v2, vgm(psill = .15, model = "Sph", 
                             range = 800, nugget = .1))
uk <- krige(log(zinc) ~ sqrt(dist), meuse.sf, newdata = grid.sf, 
              model = vm2)

tm_shape(uk) +
  tm_dots(col = "var1.pred", size = .2)
```

The predicted co-variances between zinc and cadmium are plotted.
```{r}
tm_shape(cok) +
  tm_dots(col = "cov.logCd.logZn", size = .2)
```

The map shows areas of the flood plain with high (and low) correlations between cadmium and zinc.

Obtaining a quality statistical spatial interpolation is a nuanced process but with practice kriging can be an important tool in your toolbox.

## Properly cross validating with spatial data

This material is taken from https://cran.r-project.org/web/packages/blockCV/vignettes/BlockCV_for_SDM.html

The use of spatial and environmental blocks to separate training and testing sets is needed for realistic error estimation in data with spatial correlation, and for estimating the predictive performance of models involving mapped distributions. 

Package {blockCV} provides functions to separate train and test sets using buffers, spatial and environmental blocks. It provides several options for how those blocks are constructed. It also has a function that applies geostatistical techniques to investigate the existing level of spatial autocorrelation in the explanatory variables to inform the choice of a suitable distance band by which to separate the data sets. In addition, some visualization tools are provided to help the user choose the block size and explore generated folds.

The package has been written with species distribution modeling (SDM) in mind, and the functions allow for a number of common scenarios (including presence-absence and presence-background species data, rare and common species, raster data for predictor variables), although it can be applied to any spatial model.

The package contains the raw format of the following data: Raster covariates of Australian Wet Tropic region (`.tif`) and simulated species data (`.csv`)

The raster data include several bio-climatic and topographic variables from Australian Wet Tropic region aggregated to 800 m resolution. The species data contains records of a species, simulated based on the above environmental variables for the region. There are two .csv files with presence-absence and presence-background data.

First we load the packages and import the raster data.
```{r}
library(blockCV)
library(raster)
library(sf)

awt <- raster::brick(system.file("extdata", "awt.grd", package = "blockCV"))
```

The presence absence species data include 116 presence points and 138 absence points. Spatial data can be simple features or S4 data objects. We convert the data frame to simple feature data frame as follows.
```{r}
PA.df <- read.csv(system.file("extdata", "PA.csv", package = "blockCV"))
PA.sf <- st_as_sf(PA.df, 
                  coords = c("x", "y"), 
                  crs = crs(awt))
PA.sf
```

Map these data.
```{r}
library(tmap)

tm_shape(awt[[1]]) +
  tm_raster() +
tm_shape(PA.sf[PA.sf$Species == 1,]) +
  tm_bubbles(size = .4, col = "red") +
tm_shape(PA.sf[PA.sf$Species == 0,]) +
  tm_bubbles(size = .4, col = "gray")
```

The presence background data include the 116 presence points and 10,000 random background points (0s here).
```{r}
PB.df <- read.csv(system.file("extdata", "PB.csv", package = "blockCV"))
PB.sf <- st_as_sf(PB.df, 
                  coords = c("x", "y"), 
                  crs = crs(awt))

table(PB.sf$Species)
```

The function `spatialBlock()` creates spatially separated folds based on a pre-specified distance (cell size of the blocks). It then assigns blocks to the training and testing folds with random, checkerboard pattern or in a systematic manner. The function can also divide the study region into vertical and horizontal bins with a given number of rows and columns.

The range argument (`theRange =`) needs to be in meters. When the input map has geographic coordinate system (decimal degrees), the block size is calculated by dividing `theRange =` by 111325 (the standard distance of a degree in meters, on the Equator).

The `xOffset =` and `yOffset =` can be used to shift the spatial position of the blocks in horizontal and vertical axes, respectively. This only works when the blocks have been built based on `theRange` argument. The blocks argument allows users to define an external spatial polygon as blocking layer. The polygon layer must cover all the species points. In addition, blocks can be masked by species spatial data. This option keeps the blocks that cover species data and remove the rest.

Here we block by specified range with random assignment.
```{r}
sb <- spatialBlock(speciesData = PA.sf,
                   species = "Species",
                   rasterLayer = awt,
                   theRange = 70000, # size of the blocks
                   k = 5,
                   selection = "random",
                   iteration = 100, # find evenly dispersed folds
                   biomod2Format = TRUE,
                   xOffset = 0, # shift the blocks horizontally
                   yOffset = 0)
```

Here we block by rows and columns with checkerboard assignment.
```{r}
sb2 <- spatialBlock(speciesData = PA.sf, # presence-background data
                    species = "Species",
                    rasterLayer = awt,
                    rows = 5,
                    cols = 6,
                    k = 5,
                    selection = "systematic",
                    biomod2Format = TRUE)
```

For visualizing the species data on top of the spatial blocks, one can use `geom_sf()` function of the {ggplot2} package. However, a more sophisticated way of plotting each fold separately is presented in the visualization tools section.
```{r}
library(ggplot2)

sb$plots + 
  geom_sf(data = PA.sf, alpha = 0.5)
```

The function `buffering()` generates spatially separated training and testing folds by considering buffers of specified distance around each observation point. This approach is a form of leave-one-out cross-validation. Each fold is generated by excluding nearby observations around each testing point within the specified distance (ideally the range of spatial autocorrelation). In this method the test set never directly abuts a training presence or absence.

When working with presence-background (presence and pseudo-absence) data (specified by `spDataType =` argument), only presence records are used for specifying the folds. Consider a target presence point. The buffer is defined around this target point, using the specified range (`theRange =`). The testing fold comprises the target presence point and all background points within the buffer. Any non-target presence points inside the buffer are excluded. All points (presence and background) outside of buffer are used for training set. The method cycles through all the presence data, so the number of folds is equal to the number of presence points in the dataset.

For presence-absence data, folds are created based on all records, both presences and absences. As above, a target observation (presence or absence) forms a test point, all presence and absence points other than the target point within the buffer are ignored, and the training set comprises all presences and absences outside the buffer. 

Apart from the folds, the number of training-presence, training-absence, testing-presence and testing-absence records is stored and returned in the records table. If `species = NULL` (no column with 0s and 1s is defined), the procedure is like presence-absence data. All other types of data (continuous, count or multi-class response) should be used like this.

Buffering with presence-absence data
```{r}
bf1 <- buffering(speciesData = PA.sf,
                 theRange = 70000,
                 species = "Species", # to count the number of presences and absences/backgrounds
                 spDataType = "PA", # presence-absence  data type
                 progress = TRUE)
```

In the following buffering example, presence-background data are used. By default the background data within any target point will remain in the testing fold. This can be changed by setting `addBG = FALSE` (this option only works when `spDataType = "PB"`; note the default value is `"PA"`).

Buffering with presence-background data
```{r eval=FALSE}
bf2 <- buffering(speciesData = PB.sf, # presence-background data
                 theRange = 70000,
                 species = "Species",
                 spDataType = "PB", # presence-background data type
                 addBG = TRUE, # add background data to testing folds
                 progress = TRUE)
```

The function `envBlock()` uses clustering methods to specify sets of similar environmental conditions based on the input explanatory variables. Species data corresponding to any of these groups or clusters are assigned to a fold.

As k-means algorithms use Euclidean distance to estimate clusters, the input explanatory variables should be quantitative variables. Since variables with wider ranges of values might dominate the clusters and bias the environmental clustering, all the input rasters are first standardized within the function. This is done either by normalizing based on subtracting the mean and dividing by the standard deviation of each raster (the default) or optionally by standardizing using linear scaling to constrain all raster values between 0 and 1. 

By default, the clustering is done in the raster space. In this approach, the clusters will be consistent throughout the region and across species (in the same region). However, this may result in cluster(s) that cover none of the species records especially when species data is not dispersed throughout the region or the number of clusters (k or folds) is high. In this case, the number of folds is less than the specified k. If `rasterBlock = FALSE`, the clustering will be done based only on the values of the predictors at the species presence and absence/background points. In this case, and the number of the folds will be the same as k.

Note that the input raster layer should cover all the species points, otherwise an error will rise. The records with no raster value should be deleted prior to the analysis.
```{r}
eb <- envBlock(rasterLayer = awt,
               speciesData = PA.sf,
               species = "Species",
               k = 5,
               standardization = "standard", # rescale variables between 0 and 1
               rasterBlock = FALSE,
               numLimit = 50)
```

To support a first choice of block size, prior to any model fitting, package {blockCV} includes the option for the user to look at the existing autocorrelation in the predictors, as an indication of landscape spatial structure in their study area. The tool does not suggest any absolute solution to the problem, but serves as a guide to the user. 

The function works by automatically fitting variograms to each continuous raster and finding the effective range of spatial autocorrelation. Variogram is a fundamental geostatistical tool for measuring spatial autocorrelation. It does so by assessing variability between all pairs of points. It provides information about the effective range of spatial autocorrelation which is the range over which observations are independent.
```{r}
sac <- spatialAutoRange(rasterLayer = awt,
                        sampleNumber = 5000,
                        doParallel = TRUE,
                        showPlots = TRUE)

summary(sac)

library(automap)

plot(sac$variograms[[1]])
```

Package {blockCV} provides two major visualization tools for graphical exploration of the generated folds and assisting in block size selection. These tools have been developed as local web applications using R-package shiny. With `rangeExplorer()`, the user can choose among block sizes in a specified range, visualize the resulting blocks interactively, viewing the impact of block size on number and arrangement of blocks in the landscape (and optionally on the distribution of species data in those blocks). The `foldExplorer()` tool displays folds and the number of records in each fold; it works for all three blocking methods.

Explore generated folds
```{r, eval=FALSE}
foldExplorer(blocks = sb, 
             rasterLayer = awt, 
             speciesData = PA.sf)
```

Explore the block size
```{r, eval=FALSE}
rangeExplorer(rasterLayer = awt) # the only mandatory input
```

Add species data to add them on the map
```{r, eval=FALSE}
rangeExplorer(rasterLayer = awt,
              speciesData = PA.sf,
              species = "Species",
              rangeTable = NULL,
              minRange = 30000, # limit the search domain
              maxRange = 100000)
```